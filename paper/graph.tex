\section{Graph Algorithms in MapReduce}
\label{sec:graph}

We begin with a MapReduce procedure for creating large, sparse,
randomized graphs, since they are the input for the algorithms
discussed below.  R-MAT matrices ~\cite{RMAT} are recursively
generated graphs with power-law degree distributions.  They are
commonly used to represent web and social networks.  The user
specifices six parameters that define the graph: the number of
vertices $N$ and edges $M$, and four parameters $a$, $b$, $c$, $d$
that sum to 1.0 and are discussed below.  The algorithm in
Figure~\ref{fig:rmat} uses a single MapReduce object to generate $M$
unique non-zero entries in a sparse $N \times N$ matrix $G$, where
each entry $G_{ij}$ represents an edge between graph vertices
$(V_i,V_j)$, with $V_i$ an integer from $1$ to $N$.

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxx\=xxxxxxxxxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

Input: \\
\> MapReduce object $G$ = edges of graph, initially empty \\
\\
$M_{\rm remain} = M$ \\
while $M_{\rm remain} > 0$: \\
\> Map $G$: \> Generate $M_{\rm remain}/P$ random edges $(V_i,V_j)$ on each processor \\
\> \> Output: Key = $(V_i,V_j)$, Value = NULL \\
\> Collate $G$ \\
\> Reduce $G$: \> Remove duplicate edges \\
\> \> Input: Key = $(V_i,V_j)$, MultiValue = one or more NULLs \\
\> \> Output: Key = $(V_i,V_j)$, Value = NULL \\
\> $M_{\rm remain} = M - N_{kv}$ \\
\\
Output: \\
\> MapReduce object $G$ = edges of graph: Key = $(V_i,V_j)$, Value = NULL \\

  \end{tabbing}
 \end{minipage}}\end{center}


 \caption{\it MapReduce algorithm for R-MAT graph generation on $P$
 processors, using a single MapReduce object $G$.}

 \label{fig:rmat}
\end{figure}

In the {\it map()}, each of $P$ processors generates a $1/P$ fraction
of the desired edges.  A single random edge $(V_i,V_j)$ is computed
recursively as follows.  Pick a random quadrant of the $G$ matrix with
relative probabilities $a$, $b$, $c$, and $d$.  Treat the chosen
quadrant as a sub-matrix and select a random quadrant within it, in
the same manner.  Repeat this process $n$ times where $N = 2^n$.  At
the end of the recursion, the final ``quadrant'' is a single non-zero
matrix element $G_{ij}$.

Though $G$ is very sparse, the {\it map()} typically generates some
small number of duplicate edges.  The {\it collate()} and {\it
reduce()} remove the duplicates.  The entire map-collate-reduce
sequence is repeated until the number of resulting key/value (KV)
pairs $N_{kv} = M$.  For reasonably sparse graphs this typically takes
only a few iterations.

Note that the degree distribution of vertices in the graph depends on
the choice of parameters $a$, $b$, $c$, $d$.  If one of the four
values is larger than the other three, a skewed distribution results.
Variants of the algorithm can be used when $N$ is not a power-of-two,
to generate graphs with weighted edges (assign a numeric value to the
edge), graphs without self edges (require $i \ne j$), or graphs with
undirected edges (require $i < j$).  Or the general R-MAT matrix can
be further processed by MapReduce operations to meet these
requirements.  For some algorithms below (e.g., triangle finding and
maximal independent set generation), we post-process R-MAT matrices to
create upper-triangular R-MAT matrices representing undirected graphs.
For each edge $(V_i,V_j)$ with $i > j$, we add edge $(V_j,V_i)$,
essentially symmetrizing the matrix; we then remove duplicate edges
and self edges, leaving only edges with $i < j$.

By using an additional MapReduce object, we can improve the
performance of the R-MAT generation algorithm, particularly when
out-of-core operations are needed.  In the enhanced algorithm
(Figure~\ref{fig:rmat2}), we emit newly created edges into MapReduce
object $G_{new}$ and {\it aggregate()} the edges to processors.  We
then add those edges to the MapReduce object $G$, containing all
previously generated unique edges; the edges of $G$ are already
aggregated to processors using the same mapping as $G_{new}$.  We can
use a {\it compress()} to reduce duplicates locally on each processor.
The enhanced algorithm runs faster due to the smaller number of KV
pairs communicated in the {\it aggregate()}, compared to the {\it
collate()} of the original algorithm, particularly in later iterations
of the algorithm where few new edges are generated.

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxx\=xxxxxxxxxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

Input: \\
\> MapReduce object $G$ = edges of graph, initially empty \\
\> MapReduce object $G_{new}$ = new edges of graph, initially empty \\
\\
$M_{\rm remain} = M$ \\
while $M_{\rm remain} > 0$: \\
\> Map $G_{new}$: \> Generate $M_{\rm remain}/P$ random edges $(V_i,V_j)$ on each processor \\
\> \> Output: Key = $(V_i,V_j)$, Value = NULL \\
\> Aggregate $G_{new}$ \\
\> Add $G_{new}$ to $G$, $G_{new}$ = empty \\
\> Compress $G$: \> Remove duplicate edges \\
\> \> Input: Key = $(V_i,V_j)$, MultiValue = one or more NULLs \\
\> \> Output: Key = $(V_i,V_j)$, Value = NULL \\
\> $M_{\rm remain} = M - N_{kv}$ \\
\\
Output: \\
\> MapReduce object $G$ = edges of graph: Key = $(V_i,V_j)$, Value = NULL \\

  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{\it Enhanced MapReduce algorithm for R-MAT graph generation
 on $P$ processors, using two MapReduce objects $G$ and $G_{new}$.}

 \label{fig:rmat2}
\end{figure}

\subsection{PageRank}
\label{subsec:graph_pagerank}

The PageRank algorithm assigns a relative numeric rank to each vertex
in a graph.  In an Internet context, it models the web as a directed
graph $G(V,E)$, with each vertex $V_i \in V$ representing a web page
and each edge $(V_i, V_j) \in E$ representing a hyperlink from $V_i$
to $V_j$.  The probability of moving from $V_i$ to another vertex
$V_j$ is $\alpha/d_{out}(V_i) + (1-\alpha)/|V|$, where $\alpha$ is a
user-defined parameter (usually 0.8-0.9), $d_{out}(V_i)$ is the
outdegree of vertex $V_i$, and $|V|$ is the cardinality of $V$.  The
first term represents the probability of following a given link on
page $V_i$; the second represents the probability of moving to a
random page.  For pages with no outlinks, the first term is changed to
$\alpha/|V|$, indicating equal likelihood to move to any other page.
Equivalently, the graph can be represented by a matrix
$A$~\cite{LangvilleMeyer05a}, with matrix entries $A_{ij} =
\alpha/d_{out}(V_i)$ if vertex $V_i$ links to $V_j$.  To keep $A$
sparse, terms for random jumps and zero out-degree vertices are not
explicitly stored as part of the matrix.  Rather, they are computed
separately as adjustments to the PageRank vector.  The kernel of the
PageRank algorithm is thus a power-method iteration consisting of
matrix-vector multiplications $A^T x=y$, where $x$ is the PageRank
vector from the previous iteration.  A few additional dot product and
norm computations per iteration are also required.

The algorithm in Figure~\ref{fig:pr2} performs these iterations, using
linear-algebra concepts implemented in a MapReduce framework, with
data stored in 4 MapReduce objects: $A$, $MT$, $x$, and $y$.  $A$
stores the matrix, $MT$ its ``empty'' rows, while $x$ and $y$ are
vectors of length $|V|$.  The nonzeros of matrix $A$ are initialized
as described above; the PageRank vector $x$ is initialized uniformly.
A MapReduce object $MT$ contains the indices of all-zero rows of $A$,
corresponding to vertices with no outlinks.  The PageRank algorithm is
made more efficient by invoking the {\it aggregate()} operation once
on the MapReduce objects representing the matrix $A$, the all-zero
matrix rows $MT$, and the vector $x$, before the PageRank iterations
begin.  Since these 3 MapReduce objects are all keyed by vertices,
pre-aggregating them moves all KV pairs with a given key to the same
processor.  Many of the subsequent PageRank operations then become
local operations, replacing {\it collate()} (which is equivalent to an
{\it aggregate()} followed by {\it convert()}) with simply a {\it
convert()}.  In Figure~\ref{fig:pr2}, steps where {\it convert()} is
substituted for {\it collate()} are marked with an asterisk.  This
strategy of pre-aggregating to improve data locality is useful in many
MapReduce algorithms, but assumes that identical keys in different
MapReduce objects can be mapped to the same processor.

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxx\=xxxxx\=xxxxx\=xxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

Input: \\
\> Pre-aggregated MapReduce object $A$ = $|V| \times |V|$ matrix:  Key = $i$, Value = $[j, A_{ij}]$ \\
\> Pre-aggregated MapReduce object $MT$ = indices of all-zero rows of $A$:  Key = $i$, Value = NULL \\
\> Pre-aggregated MapReduce object $x$ = initial PageRank vector:  Key = $i$, Value = $1/|V|$ \\
\> MapReduce object $y$ = vector, initially empty \\
\\
while $({residual} > {tolerance})$ \\
\> 1 Compute contribution for random jumps and zero-outdegree vertices \\
\> \> Add $x$ to $MT$ \\
$*$\> \> Convert $MT$:  Key is vertex $i$ \\
\> \> Reduce $MT$:   \\
\> \> \> Input:  Key = $i$; MultiValue = $(x_i, NULL)$ if $i \in {MT}$; MultiValue = $x_i$ if $i \notin {MT}$ \\
\> \> \> $c_{local} = c_{local} + foo$ \\
\> \> \> Output:  If ${nvalues} = 2$: Key = $i$, Value = NULL \\
\> \> $c_{global}$ = MPI\_Allreduce($c_{local}$,MPI\_SUM) \\
\> 2 Compute $y = A^T x$  \\
\> \> Copy $x$ to $y$ \\
\> \> Add $A$ to $y$ \\
$*$\> \> Convert $y$:  Key is row index of $A$ \\
\> \> Reduce $y$: \\
\> \> \>  Input: Key = $i$, Multivalue = $y_i, [j, A_{ij}]$ for nonzeros $A_{ij}$ in $A$ \\
\> \> \>  Output: Key = $j$, Value = $A_{ij} y_i$ \\
\> \> Collate $y$:  Key is column index of $A$ \\
\> \> Reduce $y$: \\
\> \> \> Input: Key = $j$, Multivalue = $A_{ij} y_i$ for nonzeroes $A_{ij}$ in column $j$ of $A$ \\
\> \> \> Output: Key = $j$, Value = $\sum_i A_{ij} y_i$ \\
\> 3 Add $c_{global}$ to $y$; compute $n_{global}$ = max element in $y$ \\
\> \> Map $y$:  \\
\> \> \> Input: Key = $i$, Value = $y_i$ \\
\> \> \> $y_i = y_i + c_{global}$; $n_{local} = {\rm max}(y_i,n_{local})$ \\
\> \> \> Output:  Key = $i$, Value = $y_i$ \\
\> \> $n_{global}$ = MPI\_Allreduce($n_{local}$,MPI\_SUM) \\
\> 4 Scale $y$ by $n_{global}$ \\
\> \> Map $y$: \\
\> \> \> Input:  Key = $i$, Value = $y_i$ \\
\> \> \> Output:  Key = $i$, Value = $y_i / {n_{global}}$ \\
\> 5 Compute residual \\
\> \> Add $y$ to $x$ \\
$*$\> \> Convert $x$:  Key is vertex $i$ \\
\> \> Reduce $x$:  \\
\> \> \> Input: Key = $i$, Multivalue = $x_i, y_i$ \\
\> \> \> $r_{local} = {\rm max}(|x_i - y_i|,r_{local})$ \\
\> \> $residual$ = MPI\_Allreduce($r_{local}$,MPI\_MAX) \\
\> 6 Copy $y$ to $x$ \\
\\
Output: \\
\> MapReduce object $x$ = PageRank vector: Key = $i$, Value = $x_i$ = numeric rank \\

  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{\it MapReduce algorithm for PageRank vertex ranking, using 4
 MapReduce objects $A$, $MT$, $x$, and $y$.  Pre-aggregating several
 of the MapReduce objects allows several communication intensive {\it
 collate()} operations to be replaced by local {\it convert()}
 operations (marked with asterisks).}

 \label{fig:pr2}
\end{figure}

In Step 1 of a PageRank interation, $MT$ is used in dot products to
compute adjustments to the PageRank vector to represent the uniform
probability of going from a leaf page to any other page.  Adjustments
for random jumps from any page are also computed.  In Step 2, the
matrix-vector product $A^T x$ is computed and the result stored in
$y$.  This is the most expensive part of the computation, requiring
two passes over the nonzero structure of $A$.  In the first pass, a
{\it convert()} gathers all local row entries $A_{ij}$ with their
associated $x_i$ entry, and a {\it reduce()} computes $A_{ij} x_i$.
In the second pass, a {\it collate()} gathers, for each $j$, all
contributions to the column sum $\sum_i A_{ij} x_i$, which is computed
by a second {\it reduce()}.  Steps 3 and 4 adjust and scale the
product vector; the work is proportional to $|V|$.  Step 5 computes
the residual to determine whether the PageRank vector has converged;
work is again proportional to $|V|$.  In Step 6, the PageRank vector
is overwritten prior to the next iteration.  Throughout the algorithm,
we exploit the ability to call MPI\_Allreduce to compute global norms
and residuals.

This linear-algebra approach is attractive because it allows
construction of the MapReduce PageRank algorithm from simple kernels
(matrix-vector multiplication, dot products) on commonly used data
types (matrices, vectors).  One can build a variety of algorithms
based on these primitives; indeed, linear-algebra toolkits such as
Trilinos~\cite{Trilinos-Overview} and PETSc~\cite{petsc-efficient}
naturally exploit this idea.  In parallel, these toolkits share
pre-computed data layouts and communication maps among distributed
objects to enable efficient operations on the objects.  In a MapReduce
context, however, separating the data into vectors and matrices
results in additional overhead to gather KV pairs with the same key
into a key-multivalue (KMV) pair.  This overhead could be reduced in
the PageRank algorithm, for example, by storing the $x$ and $y$
vectors in a single MapReduce object, with key $i$ and value $(x_i,
y_i)$.  Doing this would eliminate the {\it copy()} in Step 2 of
Figure~\ref{fig:pr2}, as well as the {\it add()} and {\it convert()}
in Step 5.  A further performance improvement would store an entire
row of $A$ along with $x$ and $y$ in a single MapReduce object, with
key $i$ and value $(x_i, y_i, d_{out}, [j_1, A_{ij_1}], [j_2,
A_{ij_2}], \dots, [j_{d_{out}}, A_ij_{d_{out}}])$ (that is, storing
together, for each vertex, its old and new PageRank value along with
all out-going edges incident to the vertex).  This data layout would
eliminate an additional {it convert()}, but at the cost of code
reusability.  This data layout would be efficient for PageRank, but is
more complex and less likely to be useful for additional algorithms.
In addition, since each KV pair must fit within a single page of
memory (in MR-MPI), storing entire matrix rows in a single KV pair
limits the size of matrices to which the algorithm can be applied.
The more general approach used in Figure~\ref{fig:pr2} of storing
non-zeros separately, enables arbitrarily large problems to be solved.
The detailed timing break-downs in
section~\ref{subsec:results_pagerank} allow estimation of the benefit
of these possible enhancements.

\subsection{Triangle enumeration}

A triangle in a graph is any triplet of vertices $(V_i,V_j,V_k)$ where
the edges $(V_i,V_j), (V_j,V_k), (V_i,V_k)$ exist.  Figure
\ref{fig:tri} outlines a MapReduce algorithm that enumerates all
triangles, assuming an input graph $G$ of undirected edges $(V_i,V_j)$
where $V_i < V_j$ for every edge, i.e. an upper-triangular R-MAT
matrix.  This exposition follows the triangle-finding algorithm
presented in~\cite{Cohen09}.

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxxx\=xxxxxx\=xxx\=xxx\=xxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

Input: \\
\> MapReduce object $G$ = edges of graph: Key = $(V_i,V_j)$ with $V_i < V_j$, Value = NULL \\
\> MapReduce object $G_0$ = edges of graph, initially empty \\
\\
1 Copy $G$ to $G_0$ \\
1 Map $G$: \> \> Convert edges to vertices \\
           \> \> \> Input: Key = $(V_i,V_j)$, Value = NULL \\
           \> \> \> Output: Key = $V_i$, Value = $V_j$ \\
           \> \> \> Output: Key = $V_j$, Value = $V_i$ \\
1 Collate $G$ \\
1 Reduce $G$: \> \> Add first degree to one vertex in edge \\
              \> \> \> Input: Key = $V_i$, MultiValue = $(V_j, V_k, ...)$ \\
	      \> \> \> for each V in MultiValue: \\
              \> \> \> \> if $V_i < V$: Output: Key = $(V_i,V)$, Value = $(D_i,0)$ \\
              \> \> \> \> else: Output: Key = $(V,V_i)$, Value = $(0,D_i)$ \\
2 Collate $G$ \\
2 Reduce $G$: \> \> Add second degree to other vertex in edge \\
              \> \> \> Input: Key = $(V_i,V_j)$, MultiValue = $((D_i,0),(0,D_j))$ \\
              \> \> \> Output: Key = $(V_i,V_j)$, Value = $(D_i,D_j)$ with $V_i < V_j$ \\
3 Map $G$: \> \> Low degree vertex emits edges \\
           \> \> \> if $D_i < D_j$: Output: Key = $V_i$, Value = $V_j$ \\
           \> \> \> else if $D_j < D_i$: Output: Key = $V_j$, Value = $V_i$ \\
           \> \> \> else: Output: Key = $V_i$, Value = $V_j$ \\
3 Collate $G$ \\
3 Reduce $G$: \> \> Emit angles of each vertex \\
              \> \> \> Input: Key = $V_i$, MultiValue = $(V_j, V_k, ...)$ \\
	      \> \> \> for each $V_1$ in MultiValue: \\
	      \> \> \> \> for each $V_2$ beyond $V_1$ in MultiValue: \\
	      \> \> \> \> \> if $V_1 < V_2$: Output: Key = $(V_1,V_2)$, Value = $V_i$ \\
	      \> \> \> \> \> else: Output: Key = $(V_2,V_1)$, Value = $V_i$ \\
4 Add $G_0$ to $G$ \\
4 Collate $G$ \\
4 Reduce $G$: \> \> Emit triangles \\
              \> \> \> Input: Key = $(V_i,V_j)$, MultiValue = $(V_k,V_l,NULL,V_m,...)$ \\
              \> \> \> if NULL exists in MultiValue: \\
	      \> \> \> \> for each non-NULL V in MultiValue: \\
	      \> \> \> \> \> Output: Key = $(V_i,V_j,V)$, Value = NULL \\
\\
Output: \\
\> MapReduce object $G$ = triangles in graph: Key = $(V_i,V_j,V_k)$, Value = NULL \\

  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{\it MapReduce algorithm for triangle enumeration, using 2 MapReduce objects $G$ and $G_0$}

 \label{fig:tri}
\end{figure}

The initial step is to store a copy of the graph edges as KV pairs in
an auxiliary MapReduce object $G_0$, for use later in the algorithm.
The first {\it map()} on $G$ converts edge keys to vertex keys with
edge values.  After a {\it collate()}, each vertex has the list of
vertices it is connected to; the first {\it reduce()} can thus flag
one vertex $V_i$ in each edge with a degree count $D_i$.  The second
{\it collate()} and {\it reduce()} assign a degree count $D_j$ to the
other vertex in each edge.  In the third {\it map()}, only the
lower-degree vertex in each edge emits its edges as KV pairs.  The
task of the third {\it reduce()} is to emit ``angles'' for each of
these low-degree vertices.  An ``angle'' is a root vertex $V_i$, with
two edges to vertices $V_1$ and $V_2$, i.e. a triangle without the
third edge $(V_1,V_2)$.  The {\it reduce()} emits a list of all angles
of vertex $V_i$, by a double loop over the edges of $V_i$.  Note that
the aggregate number of KV pairs emitted at this stage is minimized by
having only the low-degree vertex in each edge generate angles.

In stage 4, KV pairs from the original graph $G_0$ are added to the
current working set of KV pairs in MapReduce object $G$.  The KV pairs
in $G_0$ contain edges that complete triangles for the angle KV pairs
just generated.  After the fourth {\it collate()}, a pair of vertices
$(V_i,V_j)$ is the key, and the multivalue is the list of all root
vertices in angles that contain $V_i$ and $V_j$.  If the multivalue
also contains a NULL, contributed by $G_0$, then there is a
$(V_i,V_j)$ edge in the graph.  Thus all vertices in the multivalue
are roots of angles that are complete triangles and can be emitted as
a triplet key.

\subsection{Connected component labeling}

A connected component of a graph is a set of vertices where all pairs
of vertices in the set are connected by a path of edges.  A sparse
graph may contain many such components.  Figure~\ref{fig:cc} outlines
a MapReduce algorithm that labels each vertex in a graph with a
component ID.  All vertices in the same component are labelled with
the same ID, which is the ID of some vertex in the component.  We
assume an input graph $E$ of undirected edges $(V_i,V_j)$.  This
exposition also follows the connected-component algorithm presented
in~\cite{Cohen09}, with the addition of logic that load-balances data
across processors, which is important when one or a few giant
components exist in the graph.

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxx\=xxxx\=xxxx\=xxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

Input: \\
\> MapReduce object $E$ = edges of graph: Key = $(V_i,V_j)$, Value = NULL \\
\> MapReduce object $V$ = zone assignment of each vertex: Key = $V_i$, Value = $Z_i$ \\
\> MapReduce object $W$ = workspace
\\
Iterate: \\
\> 1 Map $W$ using $E$ as input: Convert edges to vertices \\
    \> \> Input: Key = $E_{ij} = (V_i, V_j)$, Value = NULL \\
    \> \> Output: Key = $V_i$, Value = $E_{ij}$ \\
    \> \> Output: Key = $V_j$, Value = $E_{ij}$ \\
\> 1 Add $V$ to $W$ \\
\> 1 Collate $W$: Vertex as key \\
\> 1 Reduce $W$: Emit edges of each vertex with zone of vertex \\
    \> \> Input: Key = $V_i$, MultiValue = $E E E E ... Z$ \\
    \> \> for each $E$ in MultiValue: \\
    \> \> \> Output: Key = $E_{ij}$, Value = $Z_i$ \\
\> 2 Collate $W$: Edge as key \\
\> 2 Reduce $W$: Emit zone re-assignments \\
       \> \> Input: Key = $E_{ij}$, MultiValue = $Z_i Z_j$ \\
       \> \> $Z_{winner}$ = min($Z_i$,$Z_j$); $Z_{loser}$ = max($Z_i$,$Z_j$) \\
       \> \> if $Z_i$ and $Z_j$ are different: \\
       \> \> \> Output: Key = $Z_{loser}$, Value = $Z_{winner}$ \\
\> 2 Exit: if $W$ is empty (no output by Reduce 2) \\
\> 3 Map $V$: Invert vertex/zone pairs \\
    \> \> Input: Key = $V_i$, Value = $Z_i$ \\
    \> \> if $Z_i$ is not partitioned: \\
    \> \> \> Output: Key = $Z_i$, Value = $V_i$ \\
    \> \> else: \\
    \> \> \> Output: Key = $Z_i^+$, Value = $V_i$ for a random processor \\
\> 4 Map $V$ using $W$ as input: Add zone reassignments in $W$ to $V$ \\
    \> \> if $Z_i$ is not partitioned: \\
    \> \> \> Output: Key = $Z_i$, Value = $Z_{winner}$ \\
    \> \> else: \\
    \> \> \> Output: Key = $Z_i^+$, Value = $Z_{winner}$ for every processor \\
    \> \> \> Output: Key = $Z_i$, Value = $Z_{winner}$ \\
\> 4 Collate $V$: Zone ID as key \\
\> 4 Reduce $V$: Emit new zone assignment of each vertex \\
       \> \> Input: Key = $Z_i$ or $Z_i^+$, MultiValue = $V V V V ... Z Z Z ...$ \\
       \> \> $Z_{new}$ = min($Z_i$ or $Z_i^+$,Z,Z,Z,...) \\
       \> \> partition $Z_{new}$ if number of $V >$ threshhold \\
       \> \> for each $V$ in MultiValue: \\
       \> \> \> Output: Key = $V_i$, Value = $Z_{new}$ \\
\\
Output: \\
\> MapReduce object $V$ = zone assignment of each vertex: Key = $V_i$, Value = $Z_i$ \\

  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{\it MapReduce algorithm for connected component labeling,
 using 3 MapReduce objects $E$, $V$, and $W$.}

 \label{fig:cc}
\end{figure}

The algorithm begins (before the iteration loop) by assigning each
vertex to its own component or ``zone,'' so that $Z_i$ = $V_i$ and
storing this assignment in MapReduce object $V$.  Each iteration grows
the zones, one layer of neighbors at a time.  As zones collide due to
shared edges, a winner is chosen (the smaller zone ID), and vertices
in the losing zone are reassigned to the winning zone.  When the
iterations complete, each zone has become a fully connected component
and the MR object $V$ holds the zone assignment for every vertex.  The
algorithm thus finds all connected components in the graph
simultaneously.  The number of iterations required depends on the
largest diameter of any component in the graph.

The first {\it map()} uses MapReduce object $E$ as input to the empty
MapReduce object $W$ to emit the vertices in each edge as keys, with
the edge as a value.  The current zone assignment of each vertex in
$V$ is added to the set of KV pairs in $W$.  The first {\it collate()}
collects all the edges of a vertex and its zone assignment together in
one multivalue.  The first {\it reduce()} re-emits each edge, tagged
by the zone assignment of one of its vertices.

Since each edge was emitted twice, the second {\it collate()} on $W$
collects the zone assignments for its two vertices together.  If the
two zone IDs are different, the second {\it reduce()} chooses a winner
(the smaller of the two IDs), and emits the loser ID as a key, with
the winning ID as a value.  If no zone ID changes are emitted, the
algorithm is finished, and the iterations cease.

The third {\it map()} inverts the vertex/zone KV pairs to become
zone/vertex KV pairs.  The partitioning logic described in
Figure~\ref{fig:cc} for this step (and subsequent ones) is described
below.  The fourth {\it map()} adds the changed zone assignments in
$W$ to the set of KV pairs in $V$.  The fourth {\it collate()} can now
collect all the vertices in each zone along with any reassignments of
that zone ID.  Since a zone could collide with multiple other zones on
the same iteration due to shared edges, the new zone ID for a zone
becomes the minimum ID of any of its neighboring zones.  If no zone
reassignment values appear in the multivalue resulting from the fourth
{\it collate()}, the zone ID is unchanged.  The final {\it reduce()}
emits a KV pair for each vertex in the zone, with the vertex as a key
and the new zone ID as a value.  This is an updated version of
MapReduce object $V$, ready to be used as input for the next
iteration.

Note that if a graph has only a few components, the fourth {\it
collate()}, which keys on the zone ID, may generate a few very large
key/multivalue (KMV) pairs.  For example, if the entire graph is fully
connected, in the last iteration, a single KMV pair assigned to one
processor will result, containing all vertices in the graph.  This
imbalance in memory and computational work can lead to poor parallel
performance of the overall algorithm.  To counter this effect, various
operations in stages 3 and 4 include extra logic.  The idea is to
partition zones whose vertex count exceeds a user-defined threshhold
into $P$ sub-zones, where $P$ is the number of processors.  The 64-bit
integer that stores the zone ID also stores a bit flag indicating the
zone has been partitioned and a set of bits that encode the processor
ID.

During the third {\it map()}, if the zone has been partitioned, the
vertex is assigned to a random processor and the processor ID bits are
added to the zone ID, as indicated by the $Z_i^+$ notation in
Figure~\ref{fig:cc}.  Likewise, if $Z_i$ has been partitioned, the
fourth {\it map()} emits the KV pair for the zone ID as
($Z_i^+$,$Z_{winner}$) instead of as ($Z_i$,$Z_{winner}$).  In this
case ($Z_i$,$Z_{winner}$), is emitted not once, but $P+1$ times, once
for each processor, and once as if $Z_i$ had not been partitioned (for
a reason discussed below).

With this additional partitioning logic, the fourth {\it collate()}
(which keys on zone IDs, some of which now include processor bits)
collects only $1/P$ of the vertices in partitioned zones onto each
processor.  Yet the multivalue on each processor still contains all
the zone-reassignments relevant to the unpartitioned zone.  Thus, the
fourth {\it reduce()} can change the zone ID (if necessary) in a
consistent manner across all $P$ multivalues that contain the zone's
vertices.  When the fourth {\it reduce()} emits new zone assignments
for each vertex, the zone retains its partitioned status; the
partition bit is also explicitly set if the vertex count exceeds the
threshhold for the first time.

Note that this logic does not guarantee that the partition bits of the
zone IDs for all the vertices in a single zone are set consistently on
a given iteration.  For example, an unpartitioned zone with a small ID
may consume a partitioned zone.  The vertices from the partitioned
zone retain their partitioned status, but the original vertices in the
small zone may not set the partition bit of their zone IDs.  On
subsequent iterations, the fourth {\it map()} emits $P+1$ copies of
new zone reassignments for both partitioned and unpartioned zone IDs,
to ensure all vertices in the zone will know the correct reassignment
information.

\subsection{Maximal independent set identification}

An ``independent'' set of vertices from a graph is one where no pair
of vertices in the set is connected by an edge.  The set is
``maximal'' if no vertex can be added to it \footnote{A maximal set is
``maximum'' if it is the largest maximal set.  Finding a graph's
maximum independent set is an NP-hard problem, which MapReduce is
unlikely to help with.}.  Finding a maximal independent set (MIS) is
useful in several contexts, such as identifying large numbers of
independent starting vertices for graph traversals.  Luby's
algorithm~\cite{Luby86} is a well-known parallel method for finding a
MIS.  Figure~\ref{fig:luby} outlines a MapReduce version of Luby's
algorithm, assuming an input graph of undirected edges $(V_i,V_j)$
where $V_i < V_j$ for every edge, i.e. an upper-triangular R-MAT
matrix.

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxx\=xxxx\=xxxx\=xxxx\=xxxx\=xxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

Input: \\
\> MapReduce object $V$ = maximal independent set vertices, initially empty \\
\> MapReduce object $E$ = edges of graph: Key = $(V_i,V_j)$ with $V_i < V_j$, Value = NULL \\
Map $E$: Assign random values consistently to each vertex $V_i$ and $V_j$ in $E$ \\
Clone $E$: Convert KV pairs in $E$ directly to KMV pairs with multivalue = NULL \\
\\
while $N_{edges}$ in $E > 0$: \\
\> 1 Reduce $E$: Determine WINNER/LOSER vertex of each edge \\
       \> \> Input: Key = $E_{ij}$, Multivalue = NULL or LOSER \\
       \> \> if multivalue = LOSER, emit nothing \\
       \> \> $V_w$ = WINNER vertex, $V_l$ = LOSER vertex \\
       \> \> Output: Key = $V_w$, Value = ($V_l$, WINNER) \\
       \> \> Output: Key = $V_l$, Value = ($V_w$, LOSER) \\
\> 1 Collate $E$: Vertex as key \\
\> 2 Reduce $E$: Find WINNER vertices \\
       \> \> Input: Key = $V_i$, MultiValue = $V V V V ...$ \\
       \> \> if all $V$ are flagged with WINNER, $V_i$ is a WINNER \\
       \> \> \> for each $V_j$ in Multivalue: \\
       \> \> \> \> Output: Key = $V_j$, Value = ($V_i$, WINNER) \\
       \> \> else: \\
       \> \> \> for each $V_j$ in Multivalue: \\
       \> \> \> \> Output: Key = $V_j$, Value = $V_i$ \\
\> 2 Collate $E$: Vertex as key \\
\> 3 Reduce $E$: Find LOSER vertices \\
       \> \> Input: Key = $V_i$, MultiValue = $V V V V ...$ \\
       \> \> if any $V$ is flagged with WINNER, $V_i$ is a LOSER \\
       \> \> \> for each $V_j$ in Multivalue: \\
       \> \> \> \> Output: Key = $V_j$, Value = ($V_i$, LOSER) \\
       \> \> else: \\
       \> \> \> for each $V_j$ in Multivalue: \\
       \> \> \> \> Output: Key = $V_j$, Value = $V_i$ \\
\> 3 Collate $E$: Vertex as key \\
\> 4 Reduce $E$: Emit WINNER vertices and LOSER edges \\
       \> \> Input: Key = $V_i$, MultiValue = $V V V V ...$ \\
       \> \> if all $V$ are flagged with LOSER, $V_i$ is a WINNER \\
       \> \> \> Output: to $V$: Key = $V_i$, Value = NULL \\
       \> \> for each $V_j$ in Multivalue: \\
       \> \> \> if $V_j$ is flagged with LOSER: \\
       \> \> \> \> Output: to $E$: Key = $E_{ij}$ with $V_i < V_j$, Value = LOSER \\
       \> \> \> else: \\
       \> \> \> \> Output: to $E$: Key = $E_{ij}$ with $V_i < V_j$, Value = NULL \\
\> 4 Collate $E$: Edge as key \\
\\
Output: \\
\> MapReduce object $V$ = maximal independent set vertices: Key = $V_i$, Value = NULL \\

  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{\it MapReduce algorithm for finding a maximal independent
 set of graph vertices via Luby's algorithm, using two MapReduce
 objects $E$ and $V$.}

 \label{fig:luby}
\end{figure}

Before the iterations begin, a random value is assigned to each vertex
(stored consistently for all edges in $E$ containing $V_i$), which is
used to compare pairs of vertices.  The vertex ID itself could be used
as the random value, but since the vertices eventually selected for
the MIS depend on the randomization, this may introduce an unwanted
bias.  Instead, a random number generator can be used to assign a
consistent random value $R_i$ to each vertex in each edge (via a {\it
map()}), which is then carried along with the vertex ID through each
stage of the algorithm.  In the notation of Figure~\ref{fig:luby},
each $V_i$ is then really two quantities, a vertex ID (1 to $N$) and
$R_i$.  Alternatively, the $R_i$ can be used to relabel the vertices
in a random manner, assigning each a new, unique vertex ID from 1 to
$N$.  In this case, $V_i$ is simply the new vertex ID, and the
vertices in the final MIS could be remapped to recover their original
IDs.  These operations can be performed with a few extra MapReduce
steps, outside the iteration loop.

The pre-iteration {\it clone()} converts the initial list of edge
key/value (KV) pairs stored in MapReduce object $E$ to key/multivalue
(KMV) pairs, with the edge as the key, and NULL as the value.  Thus,
the iterations can begin with a {\it reduce()}, without need for a
{\it collate()}.  A second empty MapReduce object $V$ is also created,
which will accumulate MIS vertices as the iterations proceed.

At each iteration, the current set of edges in $E$ is examined to
identify winning vertices.  Vertices adjacent to winners are flagged
as losers, and all edges which contain a loser vertex are marked for
removal at the start of the next iteration.  Vertices with all their
edges marked as losers are also flagged as winners.  At each iteration
marked edges are removed from the graph, and winning vertices are
added to the MIS.  When the graph is empty, the MIS is complete.

The first {\it reduce()} flags the two vertices in each edge as a
potential winner or loser.  This is done by comparing the two random
values for the vertices (or the randomized vertex IDs as explained
above).  The first {\it collate()} thus produces a multivalue for each
vertex $V_i$ which contains all the vertices it shares an edge with,
and associated winner/loser flags.

In the second {\it reduce()}, if $V_i$ won the comparison with all its
neighbor vertices, then it becomes a ``winner'' vertex.  All vertices
connected to the winner are emitted with $V_i$ tagged with a winner
flag.  If $V_i$ is not an overall winner, its neighbor vertices are
emitted without the winner flag on $V_i$..  The second {\it collate()}
collects this new information for each vertex.

In the third {\it reduce()}, if any neighbor of $V_i$ was a winner in
the previoue {\it reduce()} (indicated by a winner flag), $V_i$
becomes a ``loser'' vertex and emits all its neighbor vertices with
$V_i$ tagged with a loser flag.  Otherwise it emits all its neighbor
vertices without the loser flag on $V_i$.

In the fourth {\it reduce()}, some vertices have all their neighbor
vertices flagged as losers; these vertices become winners.  They are
either the vertices identified as winners in the second {\it
reduce()}, or vertices who would become singletons (having no edges)
when edges containing a loser vertex are removed (on the next
iteration).  These winning vertices are emitted to the MapReduce
object $V$ that stores the accumulating MIS.

All edges of each vertex are also emitted, retaining the loser flag if
they have it; they are emitted with $E_{ij} = (V_i, V_j)$ as their
key, with $V_i < V_j$.  This is to ensure both copies of the edge come
together via the fourth {\it collate()}.  The multivalue for each edge
now has two values, each of which is either NULL or a loser flag.

In the first {\it reduce()} of the next iteration, any edge with a
loser flag in its multivalue does not compare its two vertices; it is
effectively deleted from the graph.  The iterations end when all edges
have been removed from the graph.  At this point, the MapReduce object
$V$ contains a complete MIS of vertices.

\subsection{Single source shortest path calculation}

For a directed graph with weighted edges, the single-source shortest
path (SSSP) algorithm computes the shortest weighted distance from a
chosen source vertex to all other vertices in the graph.  This
calculation is straightforward when global graph information is
available.  The source vertex is labeled with distance zero.  Then in
each iteration, edge adjacencies of labeled vertices are followed, and
adjacent vertices are relabeled with updated distances.  When no
distances change, the iterations are complete.  Most importantly, only
edges adjacent to modified vertices need be visited in each iteration.

For a distributed graph, global information about edge adjacencies and
labeled vertices is not available.  Instead, following the
Bellman-Ford-style algorithm of~\cite{SSSPMapReduce, Bellman58,
Ford62}, every edge of the graph is visited in each iteration and
vertex distancs are updated.  A MapReduce formulation of this
algorithm, described in Figure~\ref{fig:sssp}, stores directed edges
in $E$ and begins by labeling the distance to all vertices as infinte,
except a distance of 0 to the source vertex $V_s$.  At each iteration,
a {\it map()} is performed using $E$ as input to add edges and their
weights to each vertex in $V$.  After a {\it collate()}, each vertex
$V_i$ knows its outgoing edges and their weights, as well as its own
current distance.  It may also have one or more distances assigned to
it from a previous iteration (from an inbound edge).  In the {\it
reduce()}, each vertex resets its distance to the minimum of these new
distances and its current distance.  If its distance changed, it emits
new distance values $d_j$ for the vertices associated with its
outgoing edges, where $d_j = d_i + w_{ij}$.  It also unsets a ``done''
flag, stored by each processor.  When the reduce is complete, an
MPI\_Allreduce is performed to check the ``done'' flag status on all
processors.  If any distance was changed, the iterations continue, and
the distance updates propagate through the graph.  If no distances
changed, the algorithm is done.

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxx\=xxxx\=xxxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

Input: \\
\> MapReduce object $E$ = graph edges with weights: Key = ($V_i, V_j$), Value = $w_{ij}$ \\
\> MapReduce object $V$ = vertices with distances from source vertex $V_s$: \\
\> \> Key = $V_i$, Value = $\infty$, except Value for $V_s$ = 0 \\
\\
while not $done$: \\
\> $done$ = 1 \\
\> Map $V$ using $E$ as input: Add edge weights in $E$ to $V$ \\
\> \> Input: Key = $E_{ij}$, Value = $w_{ij}$ \\
\> \> Output: Key = $V_i$, Value = $(V_j, w_{ij})$ \\
\> Collate $V$: Vertex is key \\
\> Reduce $V$:  Loop over edges of vertex to update distance to $V_s$ \\
\> \> Input: Key = $V_i$, Multivalue = $d_i$, edges $(V_j, w_{ij})$, candidate distances $d_j$ \\
\> \> $d_{min} = {\rm min}(d_i,d_j,d_j,\ldots)$ \\
\> \> If $d_{min} \ne d_i$: \\
\> \> \>  $done$ = 0 \\
\> \> \>  Output: Key = $V_j$, Value = $d_{min} + w_{ij}$ for each edge vertex $V_j$ \\
\> \>  Output:  Key = $V_i$, Value = $d_{min}$ \\
\> $done$ = MPI\_Allreduce($done$,MPI\_MIN) \\
\\
Output: \\
\> MapReduce object $V$ = vertices with distances from source vertex $V_s$: \\
\> \> Key = $V_i$, Value = $d_i$ \\

  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{\it MapReduce algorithm for single-source shortest path
 (SSSP) calculation, using two MapReduce objects $V$ and $E$.}

 \label{fig:sssp}
\end{figure}

As with PageRank and R-MAT generation, significant savings in
communication and execution time can be achieved by pre-aggregating
the data stored in MapReduce objects and by splitting the data
appropriately across more than one MapReduce object.  An enhanced SSSP
algorithm is shown in Figure~\ref{fig:sssp2}.  The MapReduce objects
$V$ and $E$ which store vertices and edges are aggregated across
processors only once at the beginning of the computation, which means
the communication portion of the {\it collate()} is performed to
assign each key to a processor.  The {\it collate()} of
Figure~\ref{fig:sssp} can then be replaced with a {\it compress()}
which requires no communication.

In each iteration of SSSP, typically only a small number of new
distances are generated.  The enhanced algorithm uses MapReduce object
$U$ to store these updates.  Only the updates in $U$ are communicated;
which aggregates them to the same processor that permanently stores
the corresponding vertex and its edges.  Thus, the total amount of
required communication is smaller than in the original algorithm,
which communicated all graph edges at each iteration.  Updated vertex
distances are stored in MapReduce object $V$, as before.

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxx\=xxxx\=xxxx\=xxxx\=xxxx\=xxxx\=xxxxxxxxxxxxxxxxxxxxxx\= \kill

Input: \\
\> Pre-aggregated MapReduce object $E$ = graph edges with weights: Key = ($V_i, V_j$), Value = $w_{ij}$ \\
\> Pre-aggregated MapReduce object $V$ = vertices with distances from source vertex $V_s$: \\
\> \> Key = $V_i$, Value = $\infty$, except Value for $V_s$ = 0 \\
\> MapReduce object $U$ = updates to distances, initially empty \\
\\
while not $done$: \\
\> $done$ = 1 \\
\> Aggregate $U$ \\
\> Add $U$ to $V$, $U$ = empty \\
\> Compress $V$: Compute best distance for each vertex \\
\> \> Input: Key = $V_i$, Multivalue = $d_i$, candidate distances $d_j$ \\
\> \> $d_{min} = {\rm min}(d_i,d_j,d_j,\ldots)$ \\
\> \> If $d_{min} \ne d_i$: \\
\> \> \> $done$ = 0 \\
\> \> \> Output to $U$: Key = $V_i$, Value = $d_{min}$ \\
\> \> Output to $V$: Key = $V_i$, Value = $d_{min}$ \\
\> $done$ = MPI\_Allreduce($done$,MPI\_MIN) \\
\> if not $done$: \\
\> \> Add $U$ to $E$, $U$ = empty \\
\> \> Compress $E$: Generate candidate distances for neighbors of changed vertices. \\
\> \> \> Input: Key = $V_i$, Multivalue = edges $(V_j, w_{ij})$ and $d_i$ if updated in previous step \\
\> \> \> If updated $d_i$ exists: \\
\> \> \> \> Output to $U$: Key = $V_j$, Value = $d_i+w_{ij}$ for each edge vertex $V_j$ \\
\\
Output: \\
\> MapReduce object $V$ = vertices with distances from source vertex $V_s$: \\
\> \> Key = $V_i$, Value = $d_i$ \\

  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{\it Enhanced MapReduce algorithm for single-source shortest
 path (SSSP) calculation, with an additional MapReduce object $U$.
 Pre-aggregating the vertices $V$ and edges $E$, and storing only
 changed distances in $U$, reduces communication and execution time.}

 \label{fig:sssp2}
\end{figure}
