\section{Out-of-core Issues}
\label{sec:outcore}

  what part needs to be out-of-core in MPI context
  each proc does it's own disk IO
  basic idea: modified data structures for KV and KMV
  map() operation
  aggreate() operation
  convert() operation
  reduce() operation

Since the MapReduce paradigm was designed to enable processing of
extremely large data sets, the MR-MPI library also allows for
``out-of-core'' processing, which is triggered when the KV or KMV
pairs owned by a processor do not fit in its memory.

When the user program creates a MapReduce object, the user specifies
a 
The memory available for storing key/value and key/multivalue pairs is
{\it memsize} summed across all processors.  So long as the key/value
pairs remain reasonably evenly distributed across processors then this
can be a significant amount of memory, e.g. 1 Tbyte on a
1024-processor machine.  The hash function used by the {\it collate()}
operation attempts to randomize key assignment to processors so
effective load-balance occurs.



If the set of key/value or key/multivalue pairs generated or owned by
a processor exceeds the {\it memsize} of its allocated memory, then
MR-MPI switches to ``out-of-core'' processing.  Each processor uses
temporary files to store data that does not fit in its memory.
Depending on the parallel machine's hardware configuration, these
files can reside on disks local to each processor, on the front end
(typically a NSF-mounted file system for a parallel machine), or on a
parallel file system/disk array.  The files are read/written as large
contiguous ``pages'', which are 1/4 the size of the {\it memsize}
setting discussed in the previous section.

We now explain how the MapReduce primitives described above operate in
out-of-core mode.  The {\it map()} and {\it reduce()} operations are
relatively simple.  As a {\it map()} generates key/value pairs, it
fills up a page, one key/value pair at a time.  When the page is full,
it is written to disk.  If the source of data for the {\it map()}
operation is an existing set of key/value pairs, then those datums are
read in, one page at a time, and each key/value pair is given to the
user map() function.  Similarly, a {\it reduce()} reads one page of
key/multivalue pairs from disk, passes them one at a time to the user
reduce() function, which typically generates new key/value pairs.  The
generated pairs fill up a new page, which is written to disk when
full, just as with the {\it map()} operation.  Thus for both a {\it
map()} and {\it reduce()}, out-of-core disk files are read and written
sequentially, one page at a time.

A special case is when a single key/multivalue pair is larger than a
single page.  This can happen, for example, in a connected component
finding algorithm if the graph collapses into one or a few giant
components.  In this case, the entire set of values (graph vertices
and edges) associated with the unique key (the component ID), may not
fit in one page of memory.  The individual values in the multivalue
will then be spread across as many pages as needed.  The user reduce()
function is passed a flag indicating it is receiving only a portion of
the values.  Once it has processed them, it can request a new set of
values (from a new page) from the MR-MPI library.

Performing a {\it collate()} operation out-of-core is more complex.
Recall that a collate() operation occurs in two stages.  First, keys
are hashed to ``owning'' processors and the key/value data is
communicated in an all-to-all fashion.  This is done one page of
key/value data at a time.  Each processor reads in a page of key/value
data, the communication pattern is determined (who needs what datums),
and the communication is performed.  So long as each processor
receives no more than 2x its share of the datums (one page), it has
room to receive it within the {\it memsize} restriction.  If the
key/value data is load-imbalanced so that this limit is exceeded, then
the all-to-all communication can be performed in multiple passes.

When the first stage is done, each processor now has an out-of-core
set of key/value datums that need to be reorganized into an
out-of-core set of key/multivalue pairs.  In principle, to create one
page of key/multivalue data, the entire set of key/value pairs needs
to be scanned to find all keys which contribute values to that page.
Reading all the key/value pages from disk for each page of
key/multivalue output could be prohibitively expensive.  A related
issue is that a hash table is needed to match new keys with previously
encountered keys.  But there is no guarantee that the hash table
itself will fit within the memory specified by the user via the {\it
memsize} parameter.  Our solution to these issues is to partition the
{\it memsize} memory into 3 pieces: 2 pieces each of size {\it
memsize}/4 for reading/writing pages of key/value and key/multivalue
pairs, and the remaining {\it memsize}/2 piece for a hash table.  We
can then scan the key/value pairs at most four times to produce all
the pages of key/multivalue output, as diagrammed in Figure
\ref{f:collate}.

\begin{figure}
\includegraphics[width=\textwidth,angle=-90]{fig_collate.pdf}
\caption{Four-pass algorithm for converting key/value data to
key/multivalue data.  The vertical lines represent out-of-core data
sets.  KV is key/value pairs; HT is an in-memory hash table; KMV is
key/multivalue pairs.}
\label{f:collate}
\end{figure}

\begin{itemize}

\item (Pass 1) The key/values are read and split into two files.  The
first file contains all the key/values pairs whose keys fit into the
finite-size hash table.  The second contains those which do not.

\item (Pass 2) The size of the first file (generally smaller) can be
used to estimate how many chunks the second file (generally larger)
needs to be partitioned into so that each chunk contains a set of
unique keys than can fit into the hash table.  This estimate is made
conservatively so that additional passes through the data are almost
never required.  The second pass thus reads the larger file and writes
out smaller files, similar in size to the first file created by the
first pass.

\item (Pass 3) The unique keys in each small file of key/value pairs
can now be hashed, but the file may contain more value data than will
fit in one key/multivalue page.  As each small file is read, and its
keys hashed, the accumulating hash table statistics can be used to
determine which key/values correspond to single pages of
key/multivalue output.  The key/values can thus be split into even
smaller files, one for each key/multivalue page.

\item (Pass 4) Each smaller file of key/value pairs is read, its keys
hashed, and the key/value data reorganized into sequential
key/multivalue pairs which fill a key/multivalue page, which is then
written out to disk.

\end{itemize}

Note that depending on the data set size and its key distribution all
four passes through the data may not be necessary, but the upper limit
is four, assuming the chunk-size estimations are accurate.  By
comparison, a merge sort of key/value pairs would require $log_2(N)$
passes (read/write) through the out-of-core data set, where $N$ is its
number of pages.  The MR-MPI {\it collate()} operation does not
actually sort the key/multivalue pairs by key; the final ordering is
indeterminate as it is created by the hash function.

The other MR-MPI library calls ({\it compress()}, {\it gather()},
sorting by key or value, etc) can also operate in out-of-core mode,
typically with one pass through the key/value or key/multivalue data.
Sorting is an exception, as an out-of-core merge sort requires
$log_2(N)$ passes, as just mentioned, where $N$ is the number of
pages.
