\section{Graph Algoriths in MapReduce}
\label{sec:graph}

We begin with a MapReduce procedure for creating large, sparse,
randomized graphs, since they are the input for the algorithms
discussed below.  R-MAT graphs ~\cite{RMAT} are recursively generated
graphs with power-law degree distributions.  They are commonly used to
represent web and social networks.  The user specifices 6 parameters
which define the graph: the number of vertices $N$ and edges $M$, and
4 parameters $a$, $b$, $c$, $d$ which sum to 1.0 and are discussed
below.  The algorithm in Figure \ref{fig:rmat} generates $N_z = MN$
unique non-zero entries in a sparse $NxN$ matrix $A$, where each entry
$A_{ij}$ represents an edge between graph vertices $(V_i,V_j)$.

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxx\=xxxxxxxxxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

$N_{\rm remain} = N_z$ \\
while $N_{\rm remain} > 0$: \\
\> 1 Map: \> Generate $N_{\rm remain}/P$ random edges on each processor \\
           \> \> output Key = $(V_i,V_j)$, Value = NULL \\
\> 1 Collate \\
\> 1 Reduce: \> Remove duplicate edges \\
              \> \> input Key = $(V_i,V_j)$, MultiValue = one or more NULLs \\
              \> \> output Key = $(V_i,V_j)$, Value = NULL \\
\> $N_{\rm remain} = N_z - N_{kv}$

  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{MapReduce algorithm for R-MAT graph generation.}

 \label{fig:rmat}
\end{figure}

In the map() operation, each of $P$ processors generates a $1/P$
fraction of the desired edges.  A single random $i,j$ edge is computed
recursively as follows.  Pick a random quadrant of the $A$ matrix with
relative probabilities $a$, $b$, $c$, and $d$.  Treat the chosen
quadrant as a sub-matrix and select a random quadrant within it, in
the same manner.  Repeat this process $n$ times where $N = 2^n$.  At
the end of the recursion, the final ``quadrant'' is non-zero matrix
element $A_{ij}$.

The map() will often generate some small number of duplicate edges.
The collate() and reduce() operations remove the duplicates.  The
entire map-collate-reduce sequence is repeated until the number of
resulting key/value pairs $N_{kv}$ equals $N_z$.  For reasonably
sparse graphs this typically takes only a few iterations.

Note that the degree distribution of vertices in the graph depends on
the choice of parameters $a$, $b$, $c$, $d$.  If one of the four
values is larger than the other 3, a highly skewed distribution
results.  Variants of the above algorithm can be used when $N$ is not
a power-of-two, to generate graphs with weighted edges (assign a
numeric value to the $A_{ij}$ edge), graphs without self edges
(require $i != j$), or graphs with undirected edges (require $i < $j).
Or the general R-MAT matrix can be further processed by MapReduce
operations to meet these requirements.

The PageRank algorithm assings a relative numeric rank to each
vertex in a graph.

It models the web as a directed graph $G(V,E)$, with each vertex $v
\in V$ representing a web page and each edge $e_{ij} \in E$
representing a hyperlink from $v_i$ to $v_j$.  The probability of
moving from $v_i$ to another vertex $v_j$ is $\alpha/d_{out}(v_i) +
(1-\alpha)/|V|$, where $\alpha$ is a user-defined parameter (usually
0.8-0.9), $d_{out}(v)$ is the outdegree of vertex $v$, and $|V|$ is
the cardinality of $V$.  The first term represents the probability of
following a given link on page $v_i$; the second represents the
probability of moving to a random page.  For pages with no outlinks,
the first term is $\alpha/|V|$, indicating equal likelihood to move to
any other page.  Equivalently, the graph can be represented by a
matrix $A$~\cite{LangvilleMeyer05a}, with matrix entries $A_{ij} =
\alpha/d_{out}(v_i)$ if vertex $v_i$ links to $v_j$.  The PageRank
algorithm, then, is simply a power-method iteration in which the
dominating computation is matrix-vector multiplication $A^T x=y$,
where $x$ is the PageRank vector from the previous iteration.

The algorithm in Figure \ref{fig:pr} performs these
iterations.

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxx\=xxxxxxxxxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

$N_{\rm remain} = N_z$ \\
while $N_{\rm remain} > 0$: \\
\> Map(): \> {\bf Generate} $N_{\rm remain}/P$ random edges on each processor \\
           \> \> output Key = $(V_i,V_j)$, Value = NULL \\
\> Collate() \\
\> Reduce(): \> {\bf Remove} duplicate edges \\
              \> \> input Key = $(V_i,V_j)$, MultiValue = one or more NULLs \\
              \> \> output Key = $(V_i,V_j)$, Value = NULL \\
\> $N_{\rm remain} = N_z - N_{kv}$

  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{MapReduce algorithm for PageRank vertex ranking.}

 \label{fig:pr}
\end{figure}

The MapReduce implementation performs two {\it map()} operations to
initialize the graph matrix $A$ and PageRank vector $x$.  A {\it
collate()} operation gathers all row entries $a_{ij}$ with their
associated $x_i$ entry, and a {\it reduce()} computes $a_{ij} x_i$.  A
second {\it collate()} gathers, for each $j$, all contributions to the
column sum $\sum a_{ij} x_i$, which is computed by a second {\it
reduce()}.  MPI\_Allreduce calls are used to compute global norms and
residuals.

A triangle in a graph is any triplet of vertices $(V_i,V_j,V_k)$ where
the edges $(V_i,V_j), (V_j,V_k), (V_i,V_k)$ exist.  Figure
\ref{fig:tri} outlines a MapReduce algorithm that enumerates all
triangles, assuming an input graph of undirected edges $(V_i,V_j)$
where $V_i < V_j$ for every edge, i.e. an upper-triangular R-MAT
matrix.  This exposition follows the triangle-finding algorithm
presented in \cite{Cohen}.

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxxxxxxxxxx\=xxx\=xxx\=xxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

1 Copy: \> $G_0$ = copy of edge KV pairs from input graph \\
1 Map: \> Convert edges to vertices \\
           \> \> input Key = $(V_i,V_j)$, Value = NULL \\
           \> \> output Key = $V_i$, Value = $V_j$ \\
           \> \> output Key = $V_j$, Value = $V_i$ \\
1 Collate \\
1 Reduce: \> Add first degree to one vertex in edge \\
              \> \> input Key = $V_i$, MultiValue = $(V_j, V_k, ...)$ \\
	      \> \> for each V in MultiValue: \\
              \> \> \> if $V_i < V$: output Key = $(V_i,V)$, Value = $(D_i,0)$ \\
              \> \> \> else: output Key = $(V,V_i)$, Value = $(0,D_i)$ \\
2 Collate \\
2 Reduce: \> Add second degree to other vertex in edge \\
              \> \> input Key = $(V_i,V_j)$, MultiValue = $((D_i,0),(0,D_j))$ \\
              \> \> output Key = $(V_i,V_j)$, Value = $(D_i,D_j)$ with $V_i < V_j$ \\
3 Map: \> Low degree vertex emits edges \\
           \> \> if $D_i < D_j$: output Key = $V_i$, Value = $V_j$ \\
           \> \> else if $D_j < D_i$: output Key = $V_j$, Value = $V_i$ \\
           \> \> else: output Key = $V_i$, Value = $V_j$ \\
3 Collate \\
3 Reduce: \> Emit angles of each vertex \\
              \> \> input Key = $V_i$, MultiValue = $(V_j, V_k, ...)$ \\
	      \> \> for each $V_1$ in MultiValue: \\
	      \> \> \> for each $V_2$ beyond $V_1$ in MultiValue: \\
	      \> \> \> \> if $V_1 < V_2$: output Key = $(V_1,V_2)$, Value = $V_i$ \\
	      \> \> \> \> else: output Key = $(V_2,V_1)$, Value = $V_i$ \\
4 Add: \> Add $G_0$ edge KV pairs to angle KV pairs \\
4 Collate \\
4 Reduce: \> Emit triangles \\
              \> \> input Key = $(V_i,V_j)$, MultiValue = $(V_k,V_l,NULL,V_m,...)$ \\
              \> \> if NULL exists in MultiValue: \\
	      \> \> \> for each non-NULL V in MultiValue: \\
	      \> \> \> \> output Key = $(V_i,V_j,V)$, Value = NULL

  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{MapReduce algorithm for triangle enumeration.}

 \label{fig:tri}
\end{figure}

The initial step is to store a copy of the graph edges as key/value
(KV) pairs in a auxiliary MapReduce object $G_0$, for use later in the
algorithm.  The first {\it map()} operation converts edge keys to
vertex keys with edge values.  After the {\it collate()}, each vertex
has a list of vertices it is connected to; the first {\it reduce()}
can thus flag one vertex $V_i$ in each edge with a degree count $D_i$.
The second {\it collate()} and {\it reduce()} assign a degree count
$D_j$ to the other vertex in each edge.  In the third {\it map()},
only the lower-degree vertex in each edge emits its edges as key/value
(KV) pairs.  The task of the third {\it reduce()} is to emit
``angles'' for each of these low-degree vertices.  An ``angle'' is a
root vertex $V_i$, with two edges to vertices $V_1$ and $V_2$, i.e. a
triangle without the third edge $(V_1,V_2)$.  The {\it reduce()} emits
a list of all angles of vertex $V_i$, by a double loop over the edges
of $V_i$.  Note that the aggregate volume of KV pairs emitted at this
stage is minimized by having only the low-degree vertex in each edge
generate angles.

In stage 4, the KV pairs in the original graph $G_0$ are added to the
current working set of KV pairs.  The KV pairs in $G_0$ are edges that
complete triangles for the angle KV pairs just generated.  After the
fourth {\it collate()}, a pair of vertices $(V_i,V_j)$ is the key, and
the multivalue is the list of all root vertices in angles that contain
$V_i$ and $V_j$.  If the multivalue also contains a NULL, contributed
by $G_0$, then there is a $(V_i,V_j)$ edge in the graph.  Thus all
vertices in the multivalue are roots of angles which are complete
triangles and can be emitted as a triplet key.

A connected component of a graph is a set of vertices where all pairs
of vertices in the set are connected by a path of edges.  A sparse
graph may contain many such components.  Figure \ref{fig:cc} outlines
a MapReduce algorithm that labels each vertex in a graph with a
component ID.  All vertices in the same component are labelled with
the same ID, which is the ID of a vertex in the component.  We assume
an input graph of undirected edges $(V_i,V_j)$.  This exposition also
follows the connected-component algorithm presented in \cite{Cohen},
with the addition of logic that load-balances data across processors
when one or a few giant components exist in the graph.

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxx\=xxxxxxxxxxx\=xxxx\=xxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

Iterate: \\
\> 1 Map: \> Convert edges to vertices \\
    \> \> \> input Key = $E_{ij}$, Value = NULL \\
    \> \> \> output Key = $V_i$, Value = $E_{ij}$ \\
    \> \> \> output Key = $V_j$, Value = $E_{ij}$ \\
\> 1 Add: \> Zone assignment of each vertex \\
    \> \> \> output Key = $V_i$, Value = $Z_i$ \\
\> 1 Collate: \> Vertex as key \\
\> 1 Reduce: \> Emit edges of each vertex with zone of vertex \\
       \> \> \> input Key = $V_i$, MultiValue = $E E E E ... Z$ \\
       \> \> \> for each $E$ in MultiValue: \\
      \> \> \> \> output Key = $E_{ij}$, Value = $Z_i$ \\

\> 2 Collate: \> Edge as key \\
\> 2 Reduce: \> Emit zone re-assignments \\
       \> \> \> input Key = $E_{ij}$, MultiValue = $Z_i Z_j$ \\
       \> \> \> $Z_{winner}$ = min($Z_i$,$Z_j$); $Z_{loser}$ = max($Z_i$,$Z_j$) \\
       \> \> \> if $Z_i$ and $Z_j$ are different: \\
      \> \> \> \> output Key = $Z_{loser}$, Value = $Z_{winner}$ \\
\> 2 Exit: \> if no output by Reduce 2 \\
\> 3 Map: \> Invert vertex/zone pairs \\
    \> \> \> input Key = $V_i$, Value = $Z_i$ \\
    \> \> \> if $Z_i$ is not partitioned: \\
   \> \> \> \> output Key = $Z_i$, Value = $V_i$ \\
    \> \> \> else: \\
   \> \> \> \> output Key = $Z_i^+$, Value = $V_i$ for a random processor \\
\> 3 Add: \> Changed zones ($Z_i$,$Z_{winner}$) \\
    \> \> \> if $Z_i$ is not partitioned: \\
   \> \> \> \> output Key = $Z_i$, Value = $Z_{winner}$ \\
    \> \> \> else: \\
   \> \> \> \> output Key = $Z_i^+$, Value = $Z_{winner}$ for every processor \\
   \> \> \> \> output Key = $Z_i$, Value = $Z_{winner}$ \\
\> 3 Collate: \> Zone ID as key \\
\> 3 Reduce: \> Emit new zone assignment of each vertex \\
       \> \> \> input Key = $Z_i$ or $Z_i^+$, MultiValue = $V V V V ... Z Z Z ...$ \\
       \> \> \> $Z_{new}$ = min($Z_i$ or $Z_i^+$,Z,Z,Z,...) \\
       \> \> \> partition $Z_{new}$ if number of $V$ > threshhold \\
       \> \> \> for each $V$ in MultiValue: \\
      \> \> \> \> output Key = $V_i$, Value = $Z_{new}$

  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{MapReduce algorithm for connected component labelling.}

 \label{fig:cc}
\end{figure}

The algorithm begins (before the iteration loop) by assigning each
vertex to its own component or ``zone'', so that $Z_i$ = $V_i$.  Each
iteration will grow the zones, one layer of neighbors at a time.  As
zones collide due to shared edges, a winner is chosen (the smaller
zone ID), and vertices in the losing zone are reassigned to the
winning zone.  When the iterations complete, each zone will have
become a fully connected component.  The algorithm thus finds all
connected components in the graph simultaneously.  The number of
iterations required depends on the largest diameter of any component
in the graph.

The first {\it map()} operation emits the vertices in each edge as
keys, with the edge as a value.  The current zone assignment of each
vertex is added to the set of key/value pairs.  The first collate()
operation collects all the edges of a vertex and its zone assignment
together in one multi-value.  The first reduce operation then re-emits
each edge, tagged by the zone assignment of one of its vertices.

Since each edge was emitted twice, the second collate operation
collects the zone assignments for its two vertices together.  If the
two zone IDs are different, the second reduce operation chooses a
winner (the min of the 2 IDs), and emits the loser ID as a key, with
the winning ID as a value.  If no zone ID changes are emitted, the
algorithm is finished, and the iteration exits.

The third map() operation inverts the vertex/zone key/value pairs to
become zone/vertex pairs.  The third add operation adds the changing
zone assignments to the set of key/value pairs.  The third collate()
can then collects all the vertices of a zone and zero or more
reassignments for the zone ID.  Since a zone could collide with
multiple other zones on the same iteration due to shared edges, the
new zone ID becomes the minimum ID of any of the neighboring zones.
If no zone reassignment value appears in the multi-value, the zone ID
is unchanged.  The final reduce() a key/value pair for each vertex in
the zone, with the vertex as a key and the new zone ID as a value.

Note that if a graph has only a few components, then the third collate
operation, which keys on the zone ID, may generate a few very large
key/multi-value (KMV) pairs.  For example, if the graph is fully
connected, then on the last iteration, a single KMV pair will contain
all vertices in the graph and be assigned to one processor.  This
imbalance in memory and computational work can lead to poor parallel
performance of the overall algorithm.  To counter this effect, the
various operations of stage 3 include extra logic.  The idea is to
partition zones whose vertex count exceeds a user-defined threshhold
into $P$ sub-zones, where $P$ is the number of processors.  The 64-bit
integer that stores the zone ID also stores a bit flag indicating the
zone has been partitioned and a set of bits that encode the processor
ID.

During the third map() operation, if the zone has been partitioned,
then the vertex is assigned to a random processor and the processor ID
bits are added to the zone ID, as indicated by the $Z_i^+$ notation in
Figure \ref{fig:cc}.  Likewise, if $Z_i$ has been partitioned, the
third add() operation emits the zone ID change key/value pair
($Z_i$,$Z_{winner}$) as ($Z_i^+$,$Z_{winner}$).  In this case
($Z_i$,$Z_{winner}$), is emitted not once, but $P+1$ times, once for
each processor, and once as if $Z_i$ had not been partitioned (for a
reason discussed below).

This additional partitioning logic means that the third collate()
operation, which keys on zone IDs, some of which now include processor
bits, will collect only a $1/P$ subset of the vertices in large zones
onto each processor.  But the multivalue on each processor contains
all the zone-reassignments relevant to the unpartitioned zone.  This
allows the third reduce operation to change the zone ID (if necessary)
in a consistent manner across all $P$ multi-values that contain the
zone's vertices.  When the reduce() operation emits new zone
assignments for each vertex, the zone retains its partitioned status,
and the partition bit is also explicitly set if the vertex count
exceeds the threshhold for the first time.

Note that this logic does not guarantee that the partition bits of the
zone IDs for all the vertices in a single zone will be set
consistently on a given iteration.  For example, an unpartitioned zone
with a small ID may consume a partitioned zone.  The vertices from the
partitioned zone will retain their partitioned status, but the
original vertices in the small zone may not set the partition bit of
their zone IDs.  On subsequent iterations, the third add() operation
emits $P+1$ copies of new zone reassignments for both partitioned and
unpartioned zone IDs, to insure all vertices in the zone will know the
reassignment information.

Discussion of Luby algorithm for maximally independent sets.

footnote on NP-complete for maximal; MapReduce is unlikely to
help with that issue.

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxx\=xxxxxxxxxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

$N_{\rm remain} = N_z$ \\
while $N_{\rm remain} > 0$: \\
\> Map(): \> {\bf Generate} $N_{\rm remain}/P$ random edges on each processor \\
           \> \> output: Key = $(V_i,V_j)$, Value = NULL \\
\> Collate() \\
\> Reduce(): \> {\bf Remove} duplicate edges \\
              \> \> input: Key = $(V_i,V_j)$, MultiValue = one or more NULLs \\
              \> \> output: Key = $(V_i,V_j)$, Value = NULL \\
\> $N_{\rm remain} = N_z - N_{kv}$

  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{MapReduce algorithm for R-MAT graog generation.}

 \label{fig:rmat}
\end{figure}

Discussion of SSSP.

Discuss new optimization in SSSP?

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxx\=xxxxxxxxxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

$N_{\rm remain} = N_z$ \\
while $N_{\rm remain} > 0$: \\
\> Map(): \> {\bf Generate} $N_{\rm remain}/P$ random edges on each processor \\
           \> \> output: Key = $(V_i,V_j)$, Value = NULL \\
\> Collate() \\
\> Reduce(): \> {\bf Remove} duplicate edges \\
              \> \> input: Key = $(V_i,V_j)$, MultiValue = one or more NULLs \\
              \> \> output: Key = $(V_i,V_j)$, Value = NULL \\
\> $N_{\rm remain} = N_z - N_{kv}$

  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{MapReduce algorithm for single-source shortest path (SSSP)
 determination.}

 \label{fig:rmat}
\end{figure}
