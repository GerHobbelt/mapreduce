\section{Graph Algoriths in MapReduce}
\label{sec:graph}

We begin with a MapReduce procedure for creating large, sparse,
randomized graphs, since they are the input for the algorithms
discussed below.  R-MAT graphs ~\cite{RMAT} are recursively generated
graphs with power-law degree distributions.  They are commonly used to
represent web and social networks.  The user specifices 6 parameters
which define the graph: the number of vertices $N$ and edges $M$, and
4 parameters $a$, $b$, $c$, $d$ which sum to 1.0 and are discussed
below.  The algorithm in Figure \ref{fig:rmat} generates $N_z = MN$
unique non-zero entries in a sparse $NxN$ matrix $A$, where each entry
$A_{ij}$ represents an edge between graph vertices $(V_i,V_j)$.

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxx\=xxxxxxxxxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

$N_{\rm remain} = N_z$ \\
while $N_{\rm remain} > 0$: \\
\> 1 Map: \> Generate $N_{\rm remain}/P$ random edges on each processor \\
           \> \> output Key = $(V_i,V_j)$, Value = NULL \\
\> 1 Collate \\
\> 1 Reduce: \> Remove duplicate edges \\
              \> \> input Key = $(V_i,V_j)$, MultiValue = one or more NULLs \\
              \> \> output Key = $(V_i,V_j)$, Value = NULL \\
\> $N_{\rm remain} = N_z - N_{kv}$

  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{MapReduce algorithm for R-MAT graph generation.}

 \label{fig:rmat}
\end{figure}

In the map() operation, each of $P$ processors is tasked with
generating a $1/P$ fraction of the desired edges.  A single random
$i,j$ edge is computed recursively as follows.  Pick a random quadrant
of the $A$ matrix with relative probabilities $a$, $b$, $c$, and $d$.
Treat the chosen quadrant as a sub-matrix and select a random quadrant
within it, in the same manner.  Repeat this process $n$ times where $N
= 2^n$.  At the end of the recursion, the final ``quadrant'' is
non-zero matrix element $A_{ij}$.

The map() will often generate some small number of duplicate edges.
The collate() and reduce() operations remove the duplicates.  The
entire map-collate-reduce sequence is repeated until the number of
resulting key/value pairs $N_{kv}$ equals $N_z$.  For reasonably
sparse graphs this typically takes only a few iterations.

Note that the degree distribution of vertices in the graph depends on
the choice of parameters $a$, $b$, $c$, $d$.  If one of the four
values is larger than the other 3, a highly skewed distribution
results.  Variants of the above algorithm can be used when $N$ is not
a power-of-two, to generate graphs with weighted edges (assign a
random numeric value to the $A_{ij}$ edge), graphs without self edges
(require $i != j$), or graphs with undirected edges (require $i < $j).

The PageRank algorithm assings a relative numeric rank to each
vertex in a graph.

It models the web as a directed graph $G(V,E)$, with each vertex $v
\in V$ representing a web page and each edge $e_{ij} \in E$
representing a hyperlink from $v_i$ to $v_j$.  The probability of
moving from $v_i$ to another vertex $v_j$ is $\alpha/d_{out}(v_i) +
(1-\alpha)/|V|$, where $\alpha$ is a user-defined parameter (usually
0.8-0.9), $d_{out}(v)$ is the outdegree of vertex $v$, and $|V|$ is
the cardinality of $V$.  The first term represents the probability of
following a given link on page $v_i$; the second represents the
probability of moving to a random page.  For pages with no outlinks,
the first term is $\alpha/|V|$, indicating equal likelihood to move to
any other page.  Equivalently, the graph can be represented by a
matrix $A$~\cite{LangvilleMeyer05a}, with matrix entries $A_{ij} =
\alpha/d_{out}(v_i)$ if vertex $v_i$ links to $v_j$.  The PageRank
algorithm, then, is simply a power-method iteration in which the
dominating computation is matrix-vector multiplication $A^T x=y$,
where $x$ is the PageRank vector from the previous iteration.

The algorithm in Figure \ref{fig:pr} performs these
iterations.

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxx\=xxxxxxxxxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

$N_{\rm remain} = N_z$ \\
while $N_{\rm remain} > 0$: \\
\> Map(): \> {\bf Generate} $N_{\rm remain}/P$ random edges on each processor \\
           \> \> output Key = $(V_i,V_j)$, Value = NULL \\
\> Collate() \\
\> Reduce(): \> {\bf Remove} duplicate edges \\
              \> \> input Key = $(V_i,V_j)$, MultiValue = one or more NULLs \\
              \> \> output Key = $(V_i,V_j)$, Value = NULL \\
\> $N_{\rm remain} = N_z - N_{kv}$

  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{MapReduce algorithm for PageRank vertex ranking.}

 \label{fig:pr}
\end{figure}

The MapReduce implementation performs two {\it map()} operations to
initialize the graph matrix $A$ and PageRank vector $x$.  A {\it
collate()} operation gathers all row entries $a_{ij}$ with their
associated $x_i$ entry, and a {\it reduce()} computes $a_{ij} x_i$.  A
second {\it collate()} gathers, for each $j$, all contributions to the
column sum $\sum a_{ij} x_i$, which is computed by a second {\it
reduce()}.  MPI\_Allreduce calls are used to compute global norms and
residuals.

A triangle in a graph is any triplet of vertices $(V_i,V_j,V_k)$ where
the three edges $(V_i,V_j), (V_j,V_k), (V_i,V_k)$ exist.  Figure
\ref{fig:tri} outlines a MapReduce algorithm that enumerates all such
triplets, assuming an input graph of undirected edge keys $(V_i,V_j)$
where $V_i < V_j$ for every edge, i.e. an upper-triangular R-MAT
generated matrix.  This exposition follows the triangle-finding
algorithm presented in \cite{Cohen}.

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxxxxxxxxxx\=xxx\=xxx\=xxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

1 Copy: \> $G_0$ = copy of edge KV pairs from input graph \\
1 Map: \> Convert edges to vertices \\
           \> \> input Key = $(V_i,V_j)$, Value = NULL \\
           \> \> output Key = $V_i$, Value = $V_j$ \\
           \> \> output Key = $V_j$, Value = $V_i$ \\
1 Collate \\
1 Reduce: \> Add first degree to one vertex in edge \\
              \> \> input Key = $V_i$, MultiValue = $(V_j, V_k, ...)$ \\
	      \> \> for each V in MultiValue: \\
              \> \> \> if $V_i < V$: output Key = $(V_i,V)$, Value = $(D_i,0)$ \\
              \> \> \> else: output Key = $(V,V_i)$, Value = $(0,D_i)$ \\
2 Collate \\
2 Reduce: \> Add second degree to other vertex in edge \\
              \> \> input Key = $(V_i,V_j)$, MultiValue = $((D_i,0),(0,D_j))$ \\
              \> \> output Key = $(V_i,V_j)$, Value = $(D_i,D_j)$ with $V_i < V_j$ \\
3 Map: \> Low degree vertex emits edges \\
           \> \> if $D_i < D_j$: output Key = $V_i$, Value = $V_j$ \\
           \> \> else if $D_j < D_i$: output Key = $V_j$, Value = $V_i$ \\
           \> \> else: output Key = $V_i$, Value = $V_j$ \\
3 Collate \\
3 Reduce: \> Emit angles of each vertex \\
              \> \> input Key = $V_i$, MultiValue = $(V_j, V_k, ...)$ \\
	      \> \> for each $V_1$ in MultiValue: \\
	      \> \> \> for each $V_2$ beyond $V_1$ in MultiValue: \\
	      \> \> \> \> if $V_1 < V_2$: output Key = $(V_1,V_2)$, Value = $V_i$ \\
	      \> \> \> \> else: output Key = $(V_2,V_1)$, Value = $V_i$ \\
4 Add: \> Add $G_0$ edge KV pairs to angle KV pairs \\
4 Collate \\
4 Reduce: \> Emit triangles \\
              \> \> input Key = $(V_i,V_j)$, MultiValue = $(V_k,V_l,NULL,V_m,...)$ \\
              \> \> if NULL exists in MultiValue: \\
	      \> \> \> for each non-NULL V in MultiValue: \\
	      \> \> \> \> output Key = $(V_i,V_j,V)$, Value = NULL

  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{MapReduce algorithm for triangle enumeration.}

 \label{fig:tri}
\end{figure}

The initial step is to store a copy of the graph edges as key/value
(KV) pairs in a auxiliary MapReduce object $G_0$, for use later in the
algorithm.  The first {\it map()} operation converts edge keys to
vertex keys with edge values.  After the {\it collate()}, each vertex
has a list of vertices it is connected to; the first {\it reduce()}
can thus flag one vertex $V_i$ in each edge with a degree count $D_i$.
The second {\it collate()} and {\it reduce()} assign a degree count
$D_j$ to the other vertex in each edge.  In the third {\it map()},
only the lower-degree vertex in each edge emits its edges as key/value
(KV) pairs.  The task of the third {\it reduce()} is to emit
``angles'' for each of these low-degree vertices.  An ``angle'' is a
root vertex $V_i$, with two edges to vertices $V_1$ and $V_2$, i.e. a
triangle without the third edge $(V_1,V_2)$.  The {\it reduce()} emits
a list of all angles of vertex $V_i$, by a double loop over the edges
of $V_i$.  Note that the aggregate volume of KV pairs emitted at this
stage is minimized by having only the low-degree vertex in each edge
generate angles.

In stage 4, the KV pairs in the original graph $G_0$ are added to the
current working set of KV pairs.  The KV pairs in $G_0$ are edges that
complete triangles for the angle KV pairs just generated.  After the
fourth {\it collate()}, a pair of vertices $(V_i,V_j)$ is the key, and
the multivalue is the list of all root vertices in angles that contain
$V_i$ and $V_j$.  If the multivalue also contains a NULL, contributed
by $G_0$, then there is a $(V_i,V_j)$ edge in the graph.  Thus all
vertices in the multivalue are roots of angles which are complete
triangles and can be emitted as a triplet key.

Discuss connected component identification algorithm.

Do we need differnt variants of CC?

Could just do one, discuss possible inefficiency due to giant CC.

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxx\=xxxxxxxxxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

$N_{\rm remain} = N_z$ \\
while $N_{\rm remain} > 0$: \\
\> Map(): \> {\bf Generate} $N_{\rm remain}/P$ random edges on each processor \\
           \> \> output: Key = $(V_i,V_j)$, Value = NULL \\
\> Collate() \\
\> Reduce(): \> {\bf Remove} duplicate edges \\
              \> \> input: Key = $(V_i,V_j)$, MultiValue = one or more NULLs \\
              \> \> output: Key = $(V_i,V_j)$, Value = NULL \\
\> $N_{\rm remain} = N_z - N_{kv}$

  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{MapReduce algorithm for connected component identification.}

 \label{fig:rmat}
\end{figure}

Discussion of Luby algorithm for maximally independent sets.

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxx\=xxxxxxxxxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

$N_{\rm remain} = N_z$ \\
while $N_{\rm remain} > 0$: \\
\> Map(): \> {\bf Generate} $N_{\rm remain}/P$ random edges on each processor \\
           \> \> output: Key = $(V_i,V_j)$, Value = NULL \\
\> Collate() \\
\> Reduce(): \> {\bf Remove} duplicate edges \\
              \> \> input: Key = $(V_i,V_j)$, MultiValue = one or more NULLs \\
              \> \> output: Key = $(V_i,V_j)$, Value = NULL \\
\> $N_{\rm remain} = N_z - N_{kv}$

  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{MapReduce algorithm for R-MAT graog generation.}

 \label{fig:rmat}
\end{figure}

Discussion of SSSP.

Discuss new optimization in SSSP?

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxx\=xxxxxxxxxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

$N_{\rm remain} = N_z$ \\
while $N_{\rm remain} > 0$: \\
\> Map(): \> {\bf Generate} $N_{\rm remain}/P$ random edges on each processor \\
           \> \> output: Key = $(V_i,V_j)$, Value = NULL \\
\> Collate() \\
\> Reduce(): \> {\bf Remove} duplicate edges \\
              \> \> input: Key = $(V_i,V_j)$, MultiValue = one or more NULLs \\
              \> \> output: Key = $(V_i,V_j)$, Value = NULL \\
\> $N_{\rm remain} = N_z - N_{kv}$

  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{MapReduce algorithm for single-source shortest path (SSSP)
 determination.}

 \label{fig:rmat}
\end{figure}
