\section{Graph Algorithms in MapReduce}
\label{sec:graph}

We begin with a MapReduce procedure for creating large, sparse,
randomized graphs, since they are the input for the algorithms
discussed below.  R-MAT matrices ~\cite{RMAT} are recursively
generated graphs with power-law degree distributions.  They are
commonly used to represent web and social networks.  The user
specifices six parameters that define the graph: the number of
vertices $N$ and edges $M$, and four parameters $a$, $b$, $c$, $d$
that sum to 1.0 and are discussed below.  The algorithm in
Figure~\ref{fig:rmat} generates $M$ unique non-zero entries in a
sparse $N \times N$ matrix $A$, where each entry $A_{ij}$ represents
an edge between graph vertices $(V_i,V_j)$.

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxx\=xxxxxxxxxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

$M_{\rm remain} = M$ \\
while $M_{\rm remain} > 0$: \\
\> Map: \> Generate $M_{\rm remain}/P$ random edges $(i,j)$ on each processor \\
           \> \> output Key = $(i,j)$, Value = NULL \\
\> Collate \\
\> Reduce: \> Remove duplicate edges \\
           \> \> input Key = $(i,j)$, MultiValue = one or more NULLs \\
           \> \> output Key = $(i,j)$, Value = NULL \\
\> $M_{\rm remain} = M - N_{kv}$

  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{\it MapReduce algorithm for R-MAT graph generation on $P$
 processors.}

 \label{fig:rmat}
\end{figure}

In the {\it map()} operation, each of $P$ processors generates a $1/P$
fraction of the desired edges.  A single random edge ($i,j$) is computed
recursively as follows.  Pick a random quadrant of the $A$ matrix with
relative probabilities $a$, $b$, $c$, and $d$.  Treat the chosen
quadrant as a sub-matrix and select a random quadrant within it, in
the same manner.  Repeat this process $n$ times where $N = 2^n$.  At
the end of the recursion, the final ``quadrant'' is non-zero matrix
element $A_{ij}$.

Though A is very sparse, the {\it map()} typically generates some
small number of duplicate edges.  The {\it collate()} and {\it
reduce()} operations remove the duplicates.  The entire
map-collate-reduce sequence is repeated until the number of resulting
key/value pairs $N_{kv} = M$.  For reasonably sparse graphs this
typically takes only a few iterations.

Note that the degree distribution of vertices in the graph depends on
the choice of parameters $a$, $b$, $c$, $d$.  If one of the four
values is larger than the other three, a skewed distribution results.
Variants of the above algorithm can be used when $N$ is not a
power-of-two, to generate graphs with weighted edges (assign a numeric
value to the $A_{ij}$ edge), graphs without self edges (require $i \ne
j$), or graphs with undirected edges (require $i < j$).  Or the
general R-MAT matrix can be further processed by MapReduce operations
to meet these requirements.  For some algorithms below (e.g., triangle
finding and maximal independent set generation), we post-process R-MAT
matrices to create upper-triangular R-MAT matrices representing
undirected graphs.  For each edge $(i,j)$ with $i>j$, we add edge
$(j,i)$, essentially symmetrizing the matrix; we then remove duplicate
edges and self edges, leaving only edges with $i<j$.

By using more than one MapReduce object, we can improve the
performance of the R-MAT generation algorithm, particularly when
out-of-core operations are needed.  In the enhanced algorithm
(Figure~\ref{fig:rmat2}), we emit newly created edges into MapReduce
object $E_{new}$ and {\it aggregate()} the edges to processors.  We
then add those edges to the MapReduce object $E_{old}$, containing all
previously generated unique edges; the edges of $E_{old}$ are already
aggregated to processors using the same mapping as $E_{new}$.  We can
then use the {\it compress()} function to reduce duplicates locally on
each processor.  The cost of the algorithm is reduced due to the
smaller number of KV pairs communicated in the {\it aggregate()},
compared to the {\it collate()} operation of the original algorithm,
particularly in later iterations of the algorithm where few edges are
created.

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxx\=xxxxxxxxxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

$M_{\rm remain} = M$ \\
while $M_{\rm remain} > 0$: \\
\> Map $E_{new}$: \> Generate $M_{\rm remain}/P$ random edges $(i,j)$ on each processor \\
           \> \> output Key = $(i,j)$, Value = NULL \\
\> Aggregate $E_{new}$ \\
\> Add $E_{new}$ to $E_{old}$ \\
\> Compress $E_{old}$: Remove duplicate edges \\
            \> \> input Key = $(i,j)$, MultiValue = one or more NULLs \\
            \> \> output Key = $(i,j)$, Value = NULL \\
\> $M_{\rm remain} = M - N_{kv}$

  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{\it Enhanced MapReduce algorithm for R-MAT graph generation
 on $P$ processors.}

 \label{fig:rmat2}
\end{figure}

\subsection{PageRank}
\label{subsec:graph_pagerank}

The PageRank algorithm assigns a relative numeric rank to each vertex
in a graph.  In an Internet context, it models the web as a directed
graph $G(V,E)$, with each vertex $V_i \in V$ representing a web page
and each edge $(V_i, V_j) \in E$ representing a hyperlink from $V_i$
to $V_j$.  The probability of moving from $V_i$ to another vertex
$V_j$ is $\alpha/d_{out}(V_i) + (1-\alpha)/|V|$, where $\alpha$ is a
user-defined parameter (usually 0.8-0.9), $d_{out}(V_i)$ is the
outdegree of vertex $V_i$, and $|V|$ is the cardinality of $V$.  The
first term represents the probability of following a given link on
page $V_i$; the second represents the probability of moving to a
random page.  For pages with no outlinks, the first term is
$\alpha/|V|$, indicating equal likelihood to move to any other page.
Equivalently, the graph can be represented by a matrix
$A$~\cite{LangvilleMeyer05a}, with matrix entries $A_{ij} =
\alpha/d_{out}(V_i)$ if vertex $V_i$ links to $V_j$.  To maintain the
sparsity of $A$, terms for random jumps and zero out-degree vertices
are not explicitly stored as part of the matrix.  Rather, they are
computed separately as adjustments to the PageRank vector.  The kernel
of the PageRank algorithm is thus a power-method iteration consisting
of matrix-vector multiplications $A^T x=y$, where $x$ is the PageRank
vector from the previous iteration.  A few additional dot product and
norm computations per iteration are also required.

The algorithm in Figure~\ref{fig:pr2} performs these iterations, using
linear-algebra concepts implemented in a MapReduce framework.  The
nonzeros of matrix $A$ are initialized as described above; the
PageRank vector $x$ is initialized uniformly.  A MapReduce object $MT$
contains the indices of all-zero rows of $A$, corresponding to
vertices with no outlinks.  The PageRank algorithm is made more
efficient by calling {\it aggregate()} once on the MapReduce objects
representing the matrix $A$, the all-zero matrix rows $MT$, and the
vector $x$ before the PageRank iterations begin.  Since these three
MapReduce objects have the same key types, pre-aggregating the objects
moves all KV pairs with a given key to a single processor.  Thus, many
of the PageRank operations become local operations, replacing {\it
collate()} operations (which are equivalent to an {\it aggregate()}
followed by {\it convert()}) with {\it convert()} calls.  In
Figure~\ref{fig:pr2}, steps where {\it convert()} operations can be
substituted for {\it collate()} operations are marked with an
asterisk.  This strategy of pre-aggregating to improve data locality
is useful in many MapReduce algorithms, but assumes that specific keys
are always mapped to the same processor.

In Step 1 of a PageRank interation, $MT$ is used in dot products to
compute adjustments to the PageRank vector to represent the uniform
probability of going from a leaf page to any other page.  Adjustments
for random jumps from any page are also computed.  In Step 2, the
matrix-vector product $A^T x$ is computed.  This is the most expensive
part of the computation, requiring two passes over the nonzero
structure of $A$.  In the first pass, a {\it convert()} gathers all
local row entries $A_{ij}$ with their associated $x_i$ entry, and a
{\it reduce()} computes $A_{ij} x_i$.  In the second pass, a {\it
collate()} gathers, for each $j$, all contributions to the column sum
$\sum_i A_{ij} x_i$, which is computed by a second {\it reduce()}.
Steps 3 and 4 adjust and scale the product vector; the work is
proportional to $|V|$.  Step 5 computes the residual to determine
whether the PageRank vector has converged; work is again proportional
to $|V|$.  In Step 6, the PageRank vector is overwritten prior to the
next iteration.  Throughout the algorithm, we exploit the ability to
call MPI\_Allreduce to compute global norms and residuals.

This linear-algebra approach is attractive because it allows construction
of the MapReduce PageRank algorithm from simple operations (matrix-vector
multiplication, dot products) on commonly used data types (matrices, vectors).
One can build a variety of algorithms based on these primitives;
indeed, linear-algebra toolkits such as Trilinos~\cite{Trilinos-Overview} and 
PETSc~\cite{petsc-efficient} use this exact design.  In parallel, these toolkits
share pre-computed data layouts and communication maps among distributed
objects to enable efficient operations between the objects.
For MapReduce, however, 
separating the data into vectors and matrices results in additional overhead 
to gather key-value pairs with the same key into a key-multivalue pair.  
This overhead can be reduced in PageRank, for example, by storing the
$x$ and $y$ vectors in a single MapReduce object, with key $i$ and value 
$(x_i, y_i)$.  Doing so eliminates the copy operation in Step 2 of 
Figure~\ref{fig:pr2}, as well as the add and convert operations in Step 5.
A further performance improvement would store an entire row of $A$ along with
$x$ and $y$ in a single MapReduce object, with key $i$ and value 
$(x_i, y_i, d_{out}, [j_1, A_{ij_1}], [j_2, A_{ij_2}], \dots, [j_{d_{out}}, 
A_ij_{d_{out}}])$ (that is, storing together, for each vertex, its old and
new PageRank value along with all out-going edges incident to the vertex).  
This data layout eliminates an additional convert operation, 
but at the cost of code reuse and scalability.  
While this data layout may be efficient for PageRank, it is more complex
and less likely to be useful for additional algorithms.  In addition, since
each key-value pair must fit within a single page in MR-MPI, storing entire
matrix rows in a single key-value pair limits the size of the the matrices
on which the algorithm can be applied.  The more general approach of storing
non-zeros separately enables arbitrarily large problems to be solved.
The detailed timing break-downs in section~\ref{subsec:results_pagerank} 
allow one to estimate the benefit of these implementations relative to the
code complexity and scalability.

%\begin{figure}[htb]
% \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
%  xxxx\=xxxxx\=xxxxx\=xxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxx\= \kill
%Input: \\
%\> MapReduce object $A$ containing $|V| \times |V|$ matrix:  Key = $i$, Value = $[j, A_{ij}]$ \\
%\> MapReduce object $MT$ containing indices of all-zero rows of $A$:  Key = $i$, Value = 0 \\
%\> MapReduce object $x$ containing initial PageRank vector:  Key = $i$, Value = $1/|V|$ \\
%While (${residual} > {tolerance}$) \\
%\> 1. Compute contribution for random jumps and zero-outdegree vertices \\
%\> \> Add: $x$ to $MT$ \\
%\> \> Collate $MT$:  Vertex is Key \\
%\> \> Reduce $MT$:   \\
%\> \> \> Input:  Key = $i$; MultiValue = $x_i, 0$ if $i \in {MT}$; MultiValue = $x_i$ if $i \notin {MT}$ \\
%\> \> \> Compute:  Local contributions $c_{local}$ \\
%\> \> \> Output:  If ${nvalues} = 2$, Key = $i$; Value = 0 \\
%\> \> MPI\_Allreduce $c_{local}$ with MPI\_SUM to compute global contribution $c_{global}$ \\
%\> 2. Compute $y = A^T x$ \\
%\> \> Copy $x$ to $y$ \\
%\> \> Add $A$ to $y$ \\
%\> \> Collate $y$:  Key is row index of $A$ \\
%\> \> Reduce $y$: \\
%\> \> \>  Input: Key = $i$; Multivalue = $i, [j, A_{ij}]$ for nonzeros $A_{ij}$ in $A$ \\
%\> \> \>  Output:  Key = $j$; Value = $A_{ij} y_i$ \\
%\> \> Collate $y$:  Key is column index of $A$ \\
%\> \> Reduce $y$:  \\
%\> \> \> Input:  Key = $j$; Multivalue = $A_{ij} y_i$ for all non-zero entries $A_{ij}$ of column $j$ \\
%\> \> \> Output:  Key = $j$; Value = $\sum_i A_{ij} y_i$ \\
%\> 3. Add contribution $c_{global}$ to $y$; compute local max norm $n_{local}$ of $y$ \\
%\> \> Map $y$:  \\
%\> \> \> Input:  Key = $i$, Value = $y_i$ \\
%\> \> \> Compute: $y_i = y_i + c_{global}$; if $y_i > n_{local}$, $n_{local} = y_i$ \\
%\> \> \> Output:  Key = $i$, Value = $y_i$ \\
%\> \> MPI\_Allreduce $n_{local}$ with MPI\_MAX to compute global max norm $n_{global}$ \\
%\> 4. Scale $y$ by $n_{global}$ \\
%\> \> Map $y$: \\
%\> \> \> Input:  Key = $i$, Value = $y_i$ \\
%\> \> \> Output:  Key = $i$, Value = $y_i / {n_{global}}$ \\
%\> 5. Compute residual \\
%\> \> Add $y$ to $x$ \\
%\> \> Collate $x$:  Key is index $i$ \\
%\> \> Reduce $x$: \\
%\> \> \> Input:  Key = $i$; Multivalue = $x_i, y_i$ \\
%\> \> \> Compute:  if $|x_i - y_i| > {resid}$, ${resid} = |x_i - y_i|$ \\
%\> \> MPI\_Allreduce with MPI\_MAX to compute $residual$ \\
%\> 6. $x = y$; \\
%Output:  PageRank vector $x$
  %\end{tabbing}
 %\end{minipage}}\end{center}
%
 %\caption{\it MapReduce algorithm for PageRank vertex ranking.}
%
 %\label{fig:pr}
%\end{figure}

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxx\=xxxxx\=xxxxx\=xxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

Input: \\
$*$\> Pre-aggregated MapReduce object $A$ containing $|V| \times |V|$ matrix:  Key = $i$, Value = $[j, A_{ij}]$ \\
$*$\> Pre-aggregated MapReduce object $MT$ containing indices of all-zero rows of $A$:  Key = $i$, Value = 0 \\
$*$\> Pre-aggregated MapReduce object $x$ containing initial PageRank vector:  Key = $i$, Value = $1/|V|$ \\
While (${residual} > {tolerance}$) \\
\> 1 Compute contribution for random jumps and zero-outdegree vertices \\
\> \> Add: $x$ to $MT$ \\
$*$\> \> Convert $MT$:  Vertex is Key \\
\> \> Reduce $MT$:   \\
\> \> \> Input:  Key = $i$; MultiValue = $x_i, 0$ if $i \in {MT}$; MultiValue = $x_i$ if $i \notin {MT}$ \\
\> \> \> Compute:  Local contributions $c_{local}$ \\
\> \> \> Output:  If ${nvalues} = 2$, Key = $i$; Value = 0 \\
\> \> MPI\_Allreduce $c_{local}$ with MPI\_SUM to compute global contribution $c_{global}$ \\
\> 2 Compute $y = A^T x$  \\
\> \> Copy $x$ to $y$ \\
\> \> Add $A$ to $y$ \\
$*$\> \> Convert $y$:  Key is row index of $A$ \\
\> \> Reduce $y$: \\
\> \> \>  Input: Key = $i$; Multivalue = $y_i, [j, A_{ij}]$ for nonzeros $A_{ij}$ in $A$ \\
\> \> \>  Output:  Key = $j$; Value = $A_{ij} y_i$ \\
\> \> Collate $y$:  Key is column index of $A$ \\
\> \> Reduce $y$:  \\
\> \> \> Input:  Key = $j$; Multivalue = $A_{ij} y_i$ for all non-zero entries $A_{ij}$ of column $j$ \\
\> \> \> Output:  Key = $j$; Value = $\sum_i A_{ij} y_i$ \\
\> 3 Add contribution $c_{global}$ to $y$; compute local max norm $n_{local}$ of $y$ \\
\> \> Map $y$:  \\
\> \> \> Input:  Key = $i$, Value = $y_i$ \\
\> \> \> Compute: $y_i = y_i + c_{global}$; if $y_i > {n_{local}}$, $n_{local} = y_i$ \\
\> \> \> Output:  Key = $i$, Value = $y_i$ \\
\> \> MPI\_Allreduce $n_{local}$ with MPI\_MAX to compute global max norm $n_{global}$ \\
\> 4 Scale $y$ by $n_{global}$ \\
\> \> Map $y$: \\
\> \> \> Input:  Key = $i$, Value = $y_i$ \\
\> \> \> Output:  Key = $i$, Value = $y_i / {n_{global}}$ \\
\> 5 Compute residual \\
\> \> Add $y$ to $x$ \\
$*$\> \> Convert $x$:  Key is index $i$ \\
\> \> Reduce $x$:   \\
\> \> \> Input:  Key = $i$; Multivalue = $x_i, y_i$ \\
\> \> \> Compute:  if $|x_i - y_i| > {resid}$, ${resid} = |x_i - y_i|$ \\
\> \> MPI\_Allreduce with MPI\_MAX to compute $residual$ \\
\> 6 $x = y$; \\
Output: PageRank vector $x$
  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{\it MapReduce algorithm for PageRank vertex ranking;
pre-aggregating the MapReduce objects allows many communication
intensive {\it collate()} operations to be replaced by strictly local
{\it convert()} operations (as marked with asterisks).}

 \label{fig:pr2}
\end{figure}

\subsection{Triangle enumeration}

A triangle in a graph is any triplet of vertices $(V_i,V_j,V_k)$ where
the edges $(V_i,V_j), (V_j,V_k), (V_i,V_k)$ exist.  Figure
\ref{fig:tri} outlines a MapReduce algorithm that enumerates all
triangles, assuming an input graph of undirected edges $(V_i,V_j)$
where $V_i < V_j$ for every edge, i.e. an upper-triangular R-MAT
matrix.  This exposition follows the triangle-finding algorithm
presented in~\cite{Cohen09}.

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxxxxxxxxxx\=xxx\=xxx\=xxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

1 Copy: \> $G_0$ = copy of edge KV pairs from input graph \\
1 Map: \> Convert edges to vertices \\
           \> \> input Key = $(V_i,V_j)$, Value = NULL \\
           \> \> output Key = $V_i$, Value = $V_j$ \\
           \> \> output Key = $V_j$, Value = $V_i$ \\
1 Collate \\
1 Reduce: \> Add first degree to one vertex in edge \\
              \> \> input Key = $V_i$, MultiValue = $(V_j, V_k, ...)$ \\
	      \> \> for each V in MultiValue: \\
              \> \> \> if $V_i < V$: output Key = $(V_i,V)$, Value = $(D_i,0)$ \\
              \> \> \> else: output Key = $(V,V_i)$, Value = $(0,D_i)$ \\
2 Collate \\
2 Reduce: \> Add second degree to other vertex in edge \\
              \> \> input Key = $(V_i,V_j)$, MultiValue = $((D_i,0),(0,D_j))$ \\
              \> \> output Key = $(V_i,V_j)$, Value = $(D_i,D_j)$ with $V_i < V_j$ \\
3 Map: \> Low degree vertex emits edges \\
           \> \> if $D_i < D_j$: output Key = $V_i$, Value = $V_j$ \\
           \> \> else if $D_j < D_i$: output Key = $V_j$, Value = $V_i$ \\
           \> \> else: output Key = $V_i$, Value = $V_j$ \\
3 Collate \\
3 Reduce: \> Emit angles of each vertex \\
              \> \> input Key = $V_i$, MultiValue = $(V_j, V_k, ...)$ \\
	      \> \> for each $V_1$ in MultiValue: \\
	      \> \> \> for each $V_2$ beyond $V_1$ in MultiValue: \\
	      \> \> \> \> if $V_1 < V_2$: output Key = $(V_1,V_2)$, Value = $V_i$ \\
	      \> \> \> \> else: output Key = $(V_2,V_1)$, Value = $V_i$ \\
4 Add: \> Add $G_0$ edge KV pairs to angle KV pairs \\
4 Collate \\
4 Reduce: \> Emit triangles \\
              \> \> input Key = $(V_i,V_j)$, MultiValue = $(V_k,V_l,NULL,V_m,...)$ \\
              \> \> if NULL exists in MultiValue: \\
	      \> \> \> for each non-NULL V in MultiValue: \\
	      \> \> \> \> output Key = $(V_i,V_j,V)$, Value = NULL

  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{\it MapReduce algorithm for triangle enumeration.}

 \label{fig:tri}
\end{figure}

The initial step is to store a copy of the graph edges as key/value
(KV) pairs in an auxiliary MapReduce object $G_0$, for use later in
the algorithm.  The first {\it map()} operation converts edge keys to
vertex keys with edge values.  After a {\it collate()}, each vertex
has a list of vertices it is connected to; the first {\it reduce()}
can thus flag one vertex $V_i$ in each edge with a degree count $D_i$.
The second {\it collate()} and {\it reduce()} assign a degree count
$D_j$ to the other vertex in each edge.  In the third {\it map()},
only the lower-degree vertex in each edge emits its edges KV pairs.
The task of the third {\it reduce()} is to emit ``angles'' for each of
these low-degree vertices.  An ``angle'' is a root vertex $V_i$, with
two edges to vertices $V_1$ and $V_2$, i.e. a triangle without the
third edge $(V_1,V_2)$.  The {\it reduce()} emits a list of all angles
of vertex $V_i$, by a double loop over the edges of $V_i$.  Note that
the aggregate volume of KV pairs emitted at this stage is minimized by
having only the low-degree vertex in each edge generate angles.

In stage 4, KV pairs from the original graph $G_0$ are added to the
current working set of KV pairs.  The KV pairs in $G_0$ are edges that
complete triangles for the angle KV pairs just generated.  After the
fourth {\it collate()}, a pair of vertices $(V_i,V_j)$ is the key, and
the multivalue is the list of all root vertices in angles that contain
$V_i$ and $V_j$.  If the multivalue also contains a NULL, contributed
by $G_0$, then there is a $(V_i,V_j)$ edge in the graph.  Thus all
vertices in the multivalue are roots of angles that are complete
triangles and can be emitted as a triplet key.

\subsection{Connected component labeling}

A connected component of a graph is a set of vertices where all pairs
of vertices in the set are connected by a path of edges.  A sparse
graph may contain many such components.  Figure~\ref{fig:cc} outlines
a MapReduce algorithm that labels each vertex in a graph with a
component ID.  All vertices in the same component are labelled with
the same ID, which is the ID of a vertex in the component.  We assume
an input graph of undirected edges $(V_i,V_j)$.  This exposition also
follows the connected-component algorithm presented in~\cite{Cohen09},
with the addition of logic that load-balances data across processors,
when one or a few giant components exist in the graph.

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxx\=xxxxxxxxxxx\=xxxx\=xxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

Iterate: \\
\> 1 Map: \> Convert edges to vertices \\
    \> \> \> input Key = $E_{ij} = (V_i, V_j)$, Value = NULL \\
    \> \> \> output Key = $V_i$, Value = $E_{ij}$ \\
    \> \> \> output Key = $V_j$, Value = $E_{ij}$ \\
\> 1 Add: \> Zone assignment of each vertex \\
    \> \> \> output Key = $V_i$, Value = $Z_i$ \\
\> 1 Collate: \> Vertex as key \\
\> 1 Reduce: \> Emit edges of each vertex with zone of vertex \\
       \> \> \> input Key = $V_i$, MultiValue = $E E E E ... Z$ \\
       \> \> \> for each $E$ in MultiValue: \\
      \> \> \> \> output Key = $E_{ij}$, Value = $Z_i$ \\

\> 2 Collate: \> Edge as key \\
\> 2 Reduce: \> Emit zone re-assignments \\
       \> \> \> input Key = $E_{ij}$, MultiValue = $Z_i Z_j$ \\
       \> \> \> $Z_{winner}$ = min($Z_i$,$Z_j$); $Z_{loser}$ = max($Z_i$,$Z_j$) \\
       \> \> \> if $Z_i$ and $Z_j$ are different: \\
      \> \> \> \> output Key = $Z_{loser}$, Value = $Z_{winner}$ \\
\> 2 Exit: \> if no output by Reduce 2 \\
\> 3 Map: \> Invert vertex/zone pairs \\
    \> \> \> input Key = $V_i$, Value = $Z_i$ \\
    \> \> \> if $Z_i$ is not partitioned: \\
   \> \> \> \> output Key = $Z_i$, Value = $V_i$ \\
    \> \> \> else: \\
   \> \> \> \> output Key = $Z_i^+$, Value = $V_i$ for a random processor \\
\> 3 Add: \> Changed zones ($Z_i$,$Z_{winner}$) \\
    \> \> \> if $Z_i$ is not partitioned: \\
   \> \> \> \> output Key = $Z_i$, Value = $Z_{winner}$ \\
    \> \> \> else: \\
   \> \> \> \> output Key = $Z_i^+$, Value = $Z_{winner}$ for every processor \\
   \> \> \> \> output Key = $Z_i$, Value = $Z_{winner}$ \\
\> 3 Collate: \> Zone ID as key \\
\> 3 Reduce: \> Emit new zone assignment of each vertex \\
       \> \> \> input Key = $Z_i$ or $Z_i^+$, MultiValue = $V V V V ... Z Z Z ...$ \\
       \> \> \> $Z_{new}$ = min($Z_i$ or $Z_i^+$,Z,Z,Z,...) \\
       \> \> \> partition $Z_{new}$ if number of $V >$ threshhold \\
       \> \> \> for each $V$ in MultiValue: \\
      \> \> \> \> output Key = $V_i$, Value = $Z_{new}$

  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{\it MapReduce algorithm for connected component labeling.}

 \label{fig:cc}
\end{figure}

The algorithm begins (before the iteration loop) by assigning each
vertex to its own component or ``zone,'' so that $Z_i$ = $V_i$.  Each
iteration grows the zones, one layer of neighbors at a time.  As
zones collide due to shared edges, a winner is chosen (the smaller
zone ID), and vertices in the losing zone are reassigned to the
winning zone.  When the iterations complete, each zone has
become a fully connected component.  The algorithm thus finds all
connected components in the graph simultaneously.  The number of
iterations required depends on the largest diameter of any component
in the graph.

The first {\it map()} operation emits the vertices in each edge as
keys, with the edge as a value.  The current zone assignment of each
vertex is added to the set of key/value (KV) pairs.  The first {\it
collate()} operation collects all the edges of a vertex and its zone
assignment together in one multi-value.  The first {\it reduce()}
operation re-emits each edge, tagged by the zone assignment of one of
its vertices.

Since each edge was emitted twice, the second {\it collate()}
operation collects the zone assignments for its two vertices together.
If the two zone IDs are different, the second {\it reduce()} operation
chooses a winner (the smaller of the two IDs), and emits the loser ID
as a key, with the winning ID as a value.  If no zone ID changes are
emitted, the algorithm is finished, and the iterations cease.

The third {\it map()} operation inverts the vertex/zone KV pairs to
become zone/vertex pairs.  The third {\it add()} operation adds the
changing zone assignments to the set of KV pairs.  The third {\it
collate()} can then collect all the vertices of a zone and zero or
more reassignments for the zone ID.  Since a zone could collide with
multiple other zones on the same iteration due to shared edges, the
new zone ID becomes the minimum ID of any of the neighboring zones.
If no zone reassignment value appears in the multi-value, the zone ID
is unchanged.  The final {\it reduce()} emits a KV pair for each
vertex in the zone, with the vertex as a key and the new zone ID as a
value.

Note that if a graph has only a few components, the third {\it
collate()} operation, which collates by the zone ID, may generate a
few very large key/multi-value (KMV) pairs.  For example, if the
entire graph is fully connected, in the last iteration, a single KMV
pair contains all vertices in the graph and is assigned to one
processor.  This imbalance in memory and computational work can lead
to poor parallel performance of the overall algorithm.  To counter
this effect, the various operations of stage 3 include extra logic.
The idea is to partition zones whose vertex count exceeds a
user-defined threshhold into $P$ sub-zones, where $P$ is the number of
processors.  The 64-bit integer that stores the zone ID also stores a
bit flag indicating the zone has been partitioned and a set of bits
that encode the processor ID.

During the third {\it map()} operation, if the zone has been
partitioned, the vertex is assigned to a random processor and the
processor ID bits are added to the zone ID, as indicated by the
$Z_i^+$ notation in Figure~\ref{fig:cc}.  Likewise, if $Z_i$ has been
partitioned, the third {\it add()} operation emits the zone ID change
KV pair ($Z_i$,$Z_{winner}$) as ($Z_i^+$,$Z_{winner}$).  In this case
($Z_i$,$Z_{winner}$), is emitted not once, but $P+1$ times, once for
each processor, and once as if $Z_i$ had not been partitioned (for a
reason discussed below).

With this additional partitioning logic, the third {\it collate()}
operation (which keys on zone IDs, some of which now include processor
bits) collects only $1/P$ of the vertices in large zones onto each
processor.  But the multivalue on each processor contains all the
zone-reassignments relevant to the unpartitioned zone.  Thus, the
third {\it reduce()} operation can change the zone ID (if necessary)
in a consistent manner across all $P$ multi-values that contain the
zone's vertices.  When the {\it reduce()} operation emits new zone
assignments for each vertex, the zone retains its partitioned status;
the partition bit is also explicitly set if the vertex count exceeds
the threshhold for the first time.

Note that this logic does not guarantee that the partition bits of the
zone IDs for all the vertices in a single zone are set consistently on
a given iteration.  For example, an unpartitioned zone with a small ID
may consume a partitioned zone.  The vertices from the partitioned
zone retain their partitioned status, but the original vertices in the
small zone may not set the partition bit of their zone IDs.  On
subsequent iterations, the third {\it add()} operation emits $P+1$
copies of new zone reassignments for both partitioned and unpartioned
zone IDs, to ensure all vertices in the zone know the correct
reassignment information.

\subsection{Maximal independent set identification}

An ``independent'' set of vertices from a graph is one where no pair
of vertices in the set shares an edge.  The set is ``maximal'' if no
vertex can be added \footnote{A maximal set is ``maximum'' if it is
the largest maximal set.  Finding a graph's maximum independent set is
an NP-hard problem, which MapReduce is unlikely to help with.}.
Finding a maximal independent set (MIS) is useful in several contexts,
such as identifying large numbers of independent starting vertices for
graph traversals.  Luby's algorithm~\cite{Luby86} is a well-known
parallel method for finding a MIS.  Figure~\ref{fig:luby} outlines a
MapReduce version of Luby's algorithm, assuming an input graph of
undirected edges $(V_i,V_j)$ where $V_i < V_j$ for every edge, i.e. an
upper-triangular R-MAT matrix.

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxx\=xxxxxxxxxxx\=xxxx\=xxxx\=xxxx\=xxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

Map: assign random values to each vertex $V_i$ and $V_j$ of edge $E_{ij}$. \\
Clone: convert edge KV pairs directly to KMV pairs \\
Create: empty MapReduce object MRv for maximal independent set vertices \\
\\
while $N_{edges} > 0$: \\
\> 1 Reduce: \> Determine WINNER/LOSER vertex of each edge \\
       \> \> \> input Key = $E_{ij}$ with $V_i < V_j$, Multivalue = NULL or LOSER \\
       \> \> \> if either value is LOSER, emit nothing \\
       \> \> \> $V_w$ = WINNER vertex, $V_l$ = LOSER vertex \\
       \> \> \> output Key = $V_w$, Value = $V_l$ WINNER \\
       \> \> \> output Key = $V_l$, Value = $V_w$ LOSER \\
\> 1 Collate: \> Vertex as key \\
\> 2 Reduce: \> Find WINNER vertices \\
       \> \> \> input Key = $V_i$, MultiValue = $V V V V ...$ \\
       \> \> \> if all $V$ are WINNERs: \\
      \> \> \> \> for each $V_j$ in Multivalue: \\
     \> \> \> \> \> output Key = $V_j$, Value = $V_i$ LOSER \\
       \> \> \> else: \\
      \> \> \> \> for each $V_j$ in Multivalue: \\
     \> \> \> \> \> output Key = $V_j$, Value = $V_i$ \\
\> 2 Collate: \> Vertex as key \\
\> 3 Reduce: \> Find LOSER vertices \\
       \> \> \> input Key = $V_i$, MultiValue = $V V V V ...$ \\
       \> \> \> if any $V$ is LOSER: \\
      \> \> \> \> for each $V_j$ in Multivalue: \\
     \> \> \> \> \> output Key = $V_j$, Value = $V_i$ LOSER \\
       \> \> \> else: \\
      \> \> \> \> for each $V_j$ in Multivalue: \\
     \> \> \> \> \> output Key = $V_j$, Value = $V_i$ \\
\> 3 Collate: \> Vertex as key \\
\> 4 Reduce: \> Emit WINNER vertices and LOSER edges \\
       \> \> \> input Key = $V_i$, MultiValue = $V V V V ...$ \\
       \> \> \> if all $V$ are LOSERs: \\
      \> \> \> \> output to MRv, Key = $V_i$, Value = NULL \\
       \> \> \> for each $V_j$ in Multivalue: \\
      \> \> \> \> if $V_j$ is LOSER: \\
     \> \> \> \> \> output Key = $E_{ij}$ with $V_i < V_j$, Value = LOSER \\
      \> \> \> \> else: \\
     \> \> \> \> \> output Key = $E_{ij}$ with $V_i < V_j$, Value = NULL \\
\> 4 Collate: \> Edge as key \\

  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{\it MapReduce algorithm for finding a maximal independent
 set of graph vertices via Luby's algorithm.}

 \label{fig:luby}
\end{figure}

Before the iterations begin, a random value is assigned to each
vertex, which is used to compare pairs of vertices.  The vertex ID
itself could be used as the random value, but since the vertices
eventually selected for the MIS depend on the randomization, this may
introduce an unwanted bias.  Instead a random number generator can be
used to assign a consistent random value $R_i$ to each vertex in each
edge (via a {\it map()} operation), which is then carried along with
the vertex ID through each stage of the algorithm.  In the notation of
Figure~\ref{fig:luby}, each $V_i$ is then really two quantities, a
vertex ID (1 to $N$) and $R_i$.  Alternatively, the $R_i$ can be used
to relabel the vertices in a random manner, assigning each a new,
unique vertex ID from 1 to $N$.  In this case, $V_i$ is simply the new
vertex ID, and the vertices in the final MIS could be remapped to
recover their original IDs.  These operations could be performed with
a few extra MapReduce steps, outside the iteration loop.

The pre-iteration {\it clone()} operation converts the initial list of
edge key/value (KV) pairs one by one to key/multivalue (KMV) pairs,
with the edge as the key, and NULL as the value.  Thus, the iterations
can begin with a {\it reduce()} operation, without need for a {\it
collate()} operation.  A second empty MapReduce object is also
initialized, which accumulates MIS vertices as the iterations proceed.

At each iteration, the current set of edges is examined to identify
winning vertices.  Vertices adjacent to winners are flagged as losers,
and all edges adjacent to losers are flagged for removal at the start
of the next iteration.  Vertices with all losing edges are flagged as
winners.  At each iteration edges are removed from the graph, and
winning vertices are added to the MIS.  When the graph is empty, the
MIS is complete.

The first {\it reduce()} operation flags the two vertices in each edge as a
potential winner or loser.  This is done by comparing the two random
values for the vertices (or the randomized vertex IDs as explained
above).  The first {\it collate()} operation thus produces a multivalue for
each vertex $V_i$ which contains all the vertices it shares an edge
with, and associated winner/loser flags.  In the second {\it reduce()}
operation, if $V_i$ won the comparison with all its edge neighbors,
then it is a ``winner'' vertex.  All vertices connected to the winner
are emitted with a loser flag.  If $V_i$ is not an overall winner, its
edge vertices are emitted without the loser flag.  The second
{\it collate()} operation collects this new information for each vertex.

In the third {\it reduce()} operation, if $V_i$ was flagged as a loser by
any edge neighbor who was a winner, it becomes a losing vertex
and emits all its edge vertices with a loser flag.  Otherwise it emits
all its edge vertices without the flag.

In the fourth {\it reduce()} operation, some vertices have all their
edge vertices flagged as losers.  These vertices are all winners,
either the ones identified in the second {\it reduce()} operation, or
additional vertices who would become singletons (having no edges) when
edges containing a loser vertex are removed (on the next iteration).
All of these winning vertices are emitted to the MapReduce object that
stores the accumulating MIS.

All edges of each vertex are also emitted, retaining the loser flag if
they have it; they are emitted with $E_{ij} = (V_i, V_j)$ as their
key, with $V_i < V_j$.  This is to ensure both copies of the edge come
together via the fourth {\it collate()} operation.  The multivalue for
each edge now has two values, either of which may be NULL or a loser
flag.

At the first stage of the next iteration, any edge flagged by either
value as a loser does not compare its two vertices; it is effectively
deleted from the graph.  The Luby iterations end when all edges have
been removed from the graph.  At this point, the second MapReduce
object contains a complete MIS of vertices.

\subsection{Single source shortest path calculation}

The single-source shortest path (SSSP) algorithm computes, for a
directed graph with weighted edges, the shortest weighted distance
from a chosen source vertex to all other vertices in the graph.  This
operation is straightforward when global graph information is
available.  The source vertex is labeled with distance zero.  Then in
each iteration, edge adjacencies of labeled vertices are followed, and
adjacent vertices are labeled with updated distances.  When no
distances change, the iterations are complete.  Most importantly, only
edges from modified vertices are visited in each iteration.

For distributed graphs, global information about edge adjacencies and
labeled vertices is not available.  Instead, following the
Bellman-Ford-style algorithm of~\cite{SSSPMapReduce, Bellman58,
Ford62}, every edge of the graph is visited in each iteration,
although labels for an edge's vertices are updated only if the
breadth-first traversal has reached those vertices.  A MapReduce
formulation of this algorithm, described in Figure~\ref{fig:sssp},
begins with a {\it map()} function loading edges $(V_i, V_j)$ and
source vertex $V_s$ with distance 0.  In each iteration, the edges
$(V_i, V_j)$ are collated with respect to $V_i$, and a {\it reduce()}
operation updates each $V_j$'s distance if $V_i$'s distance is
non-zero.

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxx\=xxxx\=xxxxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

Input:  \\
\> Source vertex $V_s$\\
\> MapReduce object $V$ containing graph vertices $V_i$ with distances $d_i$ from $V_s$ (initially $\infty$):  \\
\> \> Key = $V_i$; Value = $\infty$\\
\> MapReduce object $E$ containing graph edges ($V_i, V_j$) with weights $w_{ij}$: \\
\> \>  Key = $V_i$; Value = $[V_j, w_{ij}]$ \\
Map $V$:  Set distance for source vertex $V_s$ to zero \\
\> Input:  Key = $V_i$; Value = $\infty$ \\
\> Output:  Key = $V_i$; Value = 0 if $V_i = V_s$, otherwise Value = $\infty$ \\
while not $done$: \\
\> $done$ = 1; \\
\> Add: $E$ to $V$ \\
\> Collate $V$:  Key is vertex $V_i$ \\
\> Reduce $V$:  Loop over all edges to perform breadth-first search from labeled vertices \\
\> \> Input:  Key = $V_i$; Multivalue = edges $[V_j, w_{ij}]$, candidate distances $d_i$ \\
\> \> Compute:  Find smallest candidate distance $d_{min}$ for $V_i$  \\
\> \> \> If $d_{min} \ne d_i$, $done$ = 0; \\
\> \> Output:  Key = $V_i$; Value = $d_{min}$ (updated distance for $V_i$) \\
\> \> \> and if $d_{min} \ne d_i$, Key = $V_j$; Value = $d_{min} + w_{ij}$ for each edge ($V_i, V_j$) \\
\> MPI\_Allreduce on $done$ with MPI\_MIN \\
Output: MapReduce object $V$ with Key = $V_i$, Value = $d_i$. 

  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{\it MapReduce algorithm for single-source shortest path
 (SSSP) calculation.}

 \label{fig:sssp}
\end{figure}

As with PageRank and R-MAT generation, significant savings in
communication and execution time can be achieved by pre-aggregating
certain MapReduce objects and storing data in more than one MapReduce
object.  The enhanced algorithm is shown in Figure~\ref{fig:sssp2}.
The MapReduce objects storing vertices and edges are aggregated to
processors only once at the beginning of the computation.  In each
iteration of SSSP, only a small number of new candidate distances are
generated.  The enhanced algorithm uses MapReduce object $U$ to store
these updates.  Only the updates in $U$ are communicated; each update
is aggregated to the same processor that stores the corresponding
vertex and its edges.  Thus, the total amount of communication needed
is smaller than in the original algorithm, which aggregates all graph
edges in each iteration.  Updated vertex distances are stored in
MapReduce object $V$.

\begin{figure}[htb]
 \begin{center}\fbox{\begin{minipage}{\textwidth} \begin{tabbing}
  xxxx\=xxxx\=xxxx\=xxxx\=xxxx\=xxxxxxxxxxxxxxxxxxxxxxxxxx\= \kill

Input:  \\
\> Source vertex $V_s$.\\
\> Pre-aggregated MapReduce object $V$ containing graph vertices $V_i$ with distances $d_i$ from $V_s$:  \\
\> \> Key = $V_i$; Value = $\infty$.\\
\> Pre-aggregated MapReduce object $E$ containing graph edges ($V_i, V_j$) with weights $w_{ij}$: \\
\> \>  Key = $V_i$; Value = $[V_j, w_{ij}]$ \\
$U$ = new MapReduce object to store updates to distances. \\
Map $U$:  Add $V_s$ with distance $d_s = 0$ to $U$. \\
\> Input:  $V_s$ \\
\> Output:  Key = $V_s$; Value = 0. \\
while not $done$: \\
\> $done$ = 1; \\
\> Aggregate $U$. \\
\> Add $U$ to $V$. Empty $U$.\\
\> Compress $V$:  Pick best candidate distance for each vertex. \\
\> \> Input:  Key = $V_i$; Multivalue = candidate distances $d_i$. \\
\> \> Compute:  Find smallest candidate distance $d_{min}$ for $V_i$.  \\
\> \> \> If $d_{min} \ne d_i$, $done$ = 0; \\
\> \> Output to $V$:  Key = $V_i$; Value = $d_{min}$. \\
\> \> Output to $U$: if $d_{min} \ne d_i$, Key = $V_i$; Value = $d_{min}$. \\
\> MPI\_Allreduce on $done$ with MPI\_MIN. \\
\> if not $done$ \\
\> \> Add: $U$ to $E$.  Empty $U$. \\
\> \> Compress $E$:  Generate candidate distances for neighbors of changed vertices. \\
\> \> \> Input:  Key = $V_i$; Multivalue = $[V_j, w_{ij}]$ for edges ($V_i, V_j$) \\
\> \> \> \> and distance $d_i$ if updated in previous step. \\
\> \> \> Output to $U$:  If updated distance $d_i$ exists, \\
\> \> \> \> Key = $V_j$; Value = $d_i+w_{ij}$ for each edge ($V_i, V_j$). \\
Output: MapReduce object $V$ with Key = $V_i$, Value = $d_i$. 

  \end{tabbing}
 \end{minipage}}\end{center}

 \caption{\it Enhanced MapReduce algorithm for single-source shortest
 path (SSSP) calculation.  Pre-aggregating the vertices and edges, and
 later aggregating only updates to vertex distances, reduces
 communication and execution time.}

 \label{fig:sssp2}
\end{figure}
