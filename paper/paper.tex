\documentclass[11pt]{article}
\usepackage[pdftex]{graphicx}
\usepackage{url}

\setlength{\textwidth}{6.5in}
\setlength{\textheight}{9.25in}

\setlength{\voffset}{-0.0in}
\hoffset=-50pt
\topmargin=0pt
\headheight=0pt
\headsep=0pt
\evensidemargin=72pt % 1in+7pt

\setlength{\parskip}{0.5ex}
\setlength{\parindent}{1em}
\setlength{\floatsep}{1pt}
\setlength{\textfloatsep}{2pt}
\setlength{\intextsep}{2pt}

\begin{document}

\title{Map{R}educe in {MPI} for Large-scale Graph Algorithms}

\author{
Steven J.~Plimpton, Karen D.~Devine, Others? \\
Sandia National Laboratories \\
Albuquerque, NM \\
sjplimp@sandia.gov
}

\date{}

\maketitle

\centerline{Keywords: MapReduce, message-passing, MPI, graph
algorithms, R-MAT matrices}

\vspace*{0.4in}

\begin{abstract}

We describe a parallel library written with message-passing (MPI)
calls that allows algorithms to be expressed in the MapReduce
paradigm.  This means the calling program does not need to include
explicit parallel code, but instead provides ``map'' and ``reduce''
functions which operate independently on elements of a data set
distributed across processors.  The library performs needed data
movement between processors.  We describe how typical MapReduce
funtionality can be implemented in an MPI context, and also in an
out-of-core manner for data sets that do not fit within the aggregate
memory of a parallel machine.  Our motivation for creating this
library was to enable graph algorithms to be written as MapReduce
operations, allowing processing of Terabyte-scale data sets.  We
outline MapReduce versions of several such algorithms: vertex ranking
via PageRank, triangle finding, connected component identification,
Luby's algorithm for maximally independent sets, and single-source
shortest-path calculation.  To test the algorithms on arbitrarily
large artificial graphs we generate randomized R-MAT matrices in
parallel; a MapReduce version of this operation is also described.
Performance and scalability results for the various algorithms are
presented for varying size graphs on a distributed-memory cluster.
For some cases, we compare the results with non-MapReduce algorithms,
different machines, and different MapReduce software, namely Hadoop.
Our open-source library is written in C++, is callable from C++, C,
Fortran, or scripting languages such as Python, and can run on any
parallel platform that supports MPI.

\end{abstract}

\pagebreak

\input{intro}
\input{mr}
\input{outcore}
\input{graph}
\input{results}
\input{lessons}
\input{thanks}

\bibliographystyle{abbrv}
\bibliography{paper}

\end{document}
