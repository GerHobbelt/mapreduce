\section{Out-of-core Issues}
\label{sec:outcore}

Since the MapReduce paradigm was designed to enable processing of
extremely large data sets, the MR-MPI library also allows for
``out-of-core'' processing, which is triggered when the KV or KMV
pairs owned by a processor do not fit in its memory.  When this
occurs, a processor writes one or more temporary files to disk,
containing KV or KMV pairs, and reads them when required.  Depending
on the parallel machine's hardware configuration, these files can
reside on disks local to each processor, on the front end (typically a
NSF-mounted file system for a parallel machine), or on a parallel file
system/disk array.

When a user program creates a MapReduce object, a ``pagesize'' can be
specified, which defaults to 64 Mbytes.  As described below, each
MR-MPI operation, is constrained to use no more than a handful of
these pages.  The {\it pagesize} setting can be as small as 1 Mbyte or
as large as desired, though the user should insure the allocated pages
fit in physical memory, else the MR-MPI library may allocate slow
virtual memory.  The {\it pagesize} is also the typical size of
individual reads and writes to the temporary disk files; hence a
reasonable pagesize insures good I/O performance.

We now explain how the MapReduce operations described in the
preceeding section work in out-of-core mode.  The {\it map()} and {\it
reduce()} operations are relatively simple.  As a {\it map()}
generates KV pairs via the user function, a page of memory is filled
up, one KV pair at a time.  When the page is full, it is written to
disk.  If the source of data for the {\it map()} operation is an
existing set of KV pairs, then those datums are read in, one page at a
time, and a pointer to each KV pair is given to the user function.
Similarly, a {\it reduce()} reads one page of KMV pairs from disk,
passes a pointer to each pair, one at a time to the user function,
which typically generates new KV pairs.  The generated pairs fill up a
new page, which is written to disk when full, just as with the {\it
map()} operation.  Thus for both a {\it map()} and {\it reduce()},
out-of-core disk files are read and written sequentially, one page at
a time, requiring at most two pages of memory.

A special case is when a single KMV pair is larger than a single page.
This can happen, for example, in a connected component finding
algorithm if the graph collapses into one or a few giant components.
In this case, the set of values (graph vertices and edges) associated
with a unique key (the component ID), may not fit in one page of
memory.  The individual values in the multivalue will then be spread
across as many pages as needed.  The user function that processes the
KMV pair is passed a flag indicating it is receiving only a portion of
the values.  Once it has processed them, it can request a new set of
values from the MR-MPI library, which reads in a new page.

Performing a {\it collate()} operation out-of-core is more complex.
Recall that a collate() operation occurs in two stages.  First, keys
are hashed to ``owning'' processors and the KV datums are communicated
in an all-to-all fashion.  In out-of-core mode, this is done one page
of KV data at a time.  Each processor reads in a page of KV pairs, the
communication pattern for the datums in that page is determined (who
needs what datums), and all-to-all communication is performed.  Each
processor allocates a two-page chunk of memory to receive incoming KV
pairs.  On average each processor should receive KV pairs that fill
only one page; the two-page allocation allows for some load-imbalance.
If the KV pairs are distributed unevenly so that this limit is
exceeded, then the all-to-all communication is performed in smaller,
multiple passes until the full page (contributed by each processor) is
completed.  Performing an MPI\_Alltoall(), or using the custom version
provided by the MR-MPI library, requires auxiliary arrays that store
individual datum lengths and pointers.  In the worst-case scenario
(many small KV pairs), the total number of pages required to perform
the all-to-all communication, including the source and target KV pages
is 7.

When the communication stage of the {\it collate()} operation is
complete, each processor now has a set of KV pages, stored in an
out-of-core KV file, that need to be reorganized into a set of KMV
pages, stored in new out-of-core KMV file.  In principle, to create
one page of KMV pairs, requires all KV pages to be scanned to find all
the keys which contribute values to that page.  Doing this for each
output page of KMV pairs could be prohibitively expensive.  A related
issue is that a hash table is needed to match new keys with previously
encountered keys, as described in the previous section.  But there is
no guarantee that the hash table itself will not grow arbitrarily
large for some data sets with many unique keys.  We need an algorithm
for generating KMV pairs which operates within a small number of
memory pages and performs a minimal number of passes through the KV
disk file.  An algorithm that meets these goals is diagrammed in
Figure \ref{f:collate}; it requires 4 read passes of the KV pages and
3 write passes.  It also uses a finite-size in-memory hash table,
which stores unique keys as they are encountered in the loops over KV,
as well as auxiliary information needed to construct the output pages
of KMV pairs.

\begin{figure}
\includegraphics[width=\textwidth,angle=-90]{fig_collate.pdf}
\caption{Multi-pass algorithm for converting KV data to KMV data.  The
vertical lines represent out-of-core data sets.  KV is key/value
pairs; HT is an in-memory hash table; KMV is key/multivalue pairs.}
\label{f:collate}
\end{figure}

\begin{itemize}

\item (Pass 1) The KV pairs are read and split into ``partition''
files.  Each partition file contains KV pairs whose unique keys will
(likely) fit in the hash table (HT).  Intially all KV pairs are
assigned to the first partition file as the HT is populated.  When the
HT becomes full, e.g. at the point represented by the horizontal line
in a downward scan of the leftmost vertical line, then the fraction of
KV pairs read thus far is used to estimate the number of additional
partition files needed.  As subsequent KV pairs are read in, they are
written into either the original partition file or one of the new
ones.  The former if its key exists in the current HT; the latter if
not, and a subset of bits in the hash value of its key is used to
assign it to one of the partition files.  The number of needed
partition files is estimated conservatively, rounding up to the next
power-of-two, so that extra passes through the KV pairs are almost
never needed, and so the bit masking can be done quickly.  This pass
requires both a read and write of all the KV pairs.

\item (Pass 2) The KV pairs in a partition file are read, and their
unique keys are hashed into the HT, accumulating data about the number
and size of values associated with each key.  Before the next
partition file is read, passes 3 and 4 are completed for this
partition.  But eventually, this pass reads all partition files,
requiring a read of all KV pairs.

\item (Pass 3) The unique keys in the HT are scanned.  The associated
values may create KMV pairs which span many pages.  If this is the
case, the associated partition file of KV pairs is read, and assigned
to smaller ``set'' files, using the accumulated HT statistics.  Each
set file corresponds to the KV pairs which will contribute to the set
of KMV pairs that will populate one page of KMV output.  If a KMV pair
spans multiple pages, because it has a very large number of values,
then the corresponding KV pairs will still be part of a single set
file.  Eventually, this pass reads all partition files, requiring both
a read and write of all KV pairs.

\item {Pass 4) A set file is read and the key/value data for each of
its KV pairs is copied into the appropriate place in the page of KMV
pairs, using information stored in the HT.  When complete, the KMV
page is written to disk.  This pass thus eventually reads all set
files, requiring a read of all KV pairs.  It also writes all KMV
pairs.  If each KV pair has a unique key, the size of KMV output is
roughly the same as that of the KV input.

\end{itemize}

In summary, this data reorganization for the {collate()} operation is
somewhat complex, but requires a small, constant number of passes
through the data.  Namely, at most 4 read passes through the pages of
KV pairs, and 3 write passes.  The first two write passes reorganize
KV pairs into partition and set files; the final write pass creates
the KMV data set.  By contrast, a full out-of-core sort() of the KV
pairs, performed via a merge sort as discussed below, requires
$O(\log{M})$ read/write passes through the KV data, where $M$ is the
number of pages of KV pairs, which can be a large number for big data
sets.

Intermediate passes done via spool files.  Can't bound precisely,
since depends on data characteristics (see tech discussion in manual),
but generally fit wihtin 7 pages of aggregate.

Note that depending on the data set size and its key distribution all
four passes through the data may not be necessary, but the upper limit
is four, assuming the chunk-size estimations are accurate.  By
comparison, a merge sort of KV pairs would require $log_2(N)$
passes (read/write) through the out-of-core data set, where $N$ is its
number of pages.  The MR-MPI {\it collate()} operation does not
actually sort the KMV pairs by key; the final ordering is
indeterminate as it is created by the hash function.

Avoid extra passes if not needed.  E.g. one partition file, then never
even written.  First partition file not re-read to popluate HT.

Uneven distribution of unique keys in KV pair could induce extra
passes due to not enough partitions, but quite rare.



The other various MR-MPI library calls ({\it compress()}, {\it
gather(), etc}, can also operate in out-of-core mode, typically with
one pass through the KV or KMV data.  Sorting, by
key or value, is an exception.  as an out-of-core merge sort requires
$log_2(N)$ passes, as just mentioned, where $N$ is the number of
pages.
